{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection, metrics, linear_model, tree\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import scipy.sparse\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\n",
    "\n",
    "#word2vec\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('..\\\\word2vec\\\\roularta-320.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '..\\\\Data\\\\'\n",
    "\n",
    "#read data\n",
    "my_data = pd.read_csv(filepath + 'input_data_model_ling.csv', quotechar='\"', delimiter=',')\n",
    "my_train_data = pd.read_csv(filepath + 'input_data_model_ling_train.csv', quotechar='\"', delimiter=',')\n",
    "my_test_data = pd.read_csv(filepath + 'input_data_model_ling_test.csv', quotechar='\"', delimiter=',')\n",
    "\n",
    "my_train_data['test'] = False\n",
    "my_test_data['test'] = True\n",
    "my_data = my_train_data.append(my_test_data, ignore_index = True)\n",
    "\n",
    "#fill up NULL values in the original data with 0\n",
    "my_data['fraction_total_changed_intro_original'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_intro_new'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_text_original'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_text_new'].fillna(0, inplace=True) \n",
    "my_data['original_changed_text'].fillna('', inplace=True) \n",
    "my_data['new_changed_text'].fillna('', inplace=True) \n",
    "my_data['topic'].fillna('other', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the appropriate learning algorithm and language model\n",
    "\n",
    "#LEARNING ALGORITHM\n",
    "alg = 'logistic regression'\n",
    "#alg = 'decision tree'\n",
    "#alg = 'support vector machine'\n",
    "\n",
    "#LANGUAGE MODEL\n",
    "\n",
    "#lang = 'no text'\n",
    "#lang = 'tf-idf'\n",
    "#lang = 'word2vec'\n",
    "#lang = 'bertje_full'\n",
    "lang = 'bertje_minimized'\n",
    "#lang = 'bertje_lemmatized'\n",
    "#lang = 'sbert_full'\n",
    "#lang = 'sbert_minimized'\n",
    "#lang = 'sbert_lemmatized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    17119\n",
      "True      4010\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#show distribution of positive and negative samples\n",
    "print(my_data['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the features to be inputted to the model\n",
    "\n",
    "my_data['original_time'] = pd.to_datetime(my_data['original_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "my_data['new_time'] = pd.to_datetime(my_data['new_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "my_data['first_time'] = pd.to_datetime(my_data['first_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "my_data['weekday_original'] = my_data['original_time'].dt.weekday\n",
    "my_data['hour_original'] = my_data['original_time'].dt.hour\n",
    "my_data['weekday_new'] = my_data['new_time'].dt.weekday\n",
    "my_data['hour_new'] = my_data['new_time'].dt.hour\n",
    "my_data['weekday_first'] = my_data['first_time'].dt.weekday\n",
    "my_data['hour_first'] = my_data['first_time'].dt.hour\n",
    "\n",
    "data_to_encode = my_data[['newspaper', 'topic', 'textpart', 'first_wordtype', 'last_wordtype']]\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe_data = pd.DataFrame(ohe.fit_transform(data_to_encode))\n",
    "\n",
    "normalized_continuous_array = ['weekday_original', 'weekday_new', 'hour_original', 'hour_new',\n",
    "    'length_original', 'length_new', 'max_version_number', \n",
    "                               'version_number_progress',\n",
    "                                 'dates_difference', \n",
    "                               'time_difference', 'original_title_length', 'original_intro_length',\n",
    "               'original_text_length', 'new_title_length', 'new_intro_length', 'new_text_length', \n",
    "                               'fraction_original_title_changed', 'fraction_new_title_changed',\n",
    "              'fraction_original_intro_changed', 'fraction_new_intro_changed',\n",
    "              'fraction_original_text_changed', 'fraction_new_text_changed', \n",
    "                                 'original_changed_fraction_text_part', 'new_changed_fraction_text_part', \n",
    "                'levenshtein_maximalized',\n",
    "                               'nr_insert_max', 'nr_delete_max', 'nr_replace_max',\n",
    "              'levenshtein_minimalized',\n",
    "                               'nr_insert_min', 'nr_delete_min', 'nr_replace_min',\n",
    "                               'jaccard', 'capitalized_equality',\n",
    "    'seqratio', 'text_overlap_original', 'text_overlap_new',\n",
    "              'stop_words_ratio',\n",
    "                               'fraction_total_changed_original', 'fraction_total_changed_new',\n",
    "                            'fraction_total_changed_title_original', 'fraction_total_changed_title_new',\n",
    "              'fraction_total_changed_intro_original', 'fraction_total_changed_intro_new',\n",
    "              'fraction_total_changed_text_original', 'fraction_total_changed_text_new',\n",
    "            'ent_original', 'original_token_length', 'adv_orig', 'noun_orig', 'point_orig', 'comma_orig',\n",
    "              'accent_orig', 'haakje_orig', 'doublepoint_orig', 'hyphen_orig', 'threepoints_orig', 'punct_orig', 'x_orig', 'propn_orig',\n",
    "              'pron_orig', 'det_orig', 'sconj_orig', 'space_orig', 'sym_orig', 'num_orig', 'adp_orig',\n",
    "              'intj_orig', 'aux_orig', 'inf_orig', 'pv_verl_ev_orig', 'pv_verl_mv_orig', 'pv_tgw_ev_orig', 'pv_tgw_mv_orig',\n",
    "                'od_prenom_orig', 'od_nom_orig', 'od_postnom_orig', 'od_vrij_orig', 'vd_vrij_orig', 'vd_prenom_orig', \n",
    "              'vd_postnom_orig', 'vd_nom_orig', 'verb_orig', 'cconj_orig', 'adj_sup_orig', 'adj_comp_orig', 'adj_basis_orig',\n",
    "              'ent_new', 'new_token_length', 'adv_new', 'noun_new', 'point_new', 'comma_new',\n",
    "              'accent_new', 'haakje_new', 'doublepoint_new', 'hyphen_new', 'threepoints_new', 'punct_new', 'x_new', 'propn_new',\n",
    "              'pron_new', 'det_new', 'sconj_new', 'space_new', 'sym_new', 'num_new', 'adp_new',\n",
    "              'intj_new', 'aux_new', 'inf_new', 'pv_verl_ev_new', 'pv_verl_mv_new', 'pv_tgw_ev_new', 'pv_tgw_mv_new',\n",
    "                'od_prenom_new', 'od_nom_new', 'od_postnom_new', 'od_vrij_new', 'vd_vrij_new', 'vd_prenom_new', \n",
    "              'vd_postnom_new', 'vd_nom_new', 'verb_new', 'cconj_new', 'adj_sup_new', 'adj_comp_new', 'adj_basis_new',  \n",
    "              'orginal_spelling_ok', 'new_spelling_ok', 'number_comparison', 'changed_position',\n",
    "                               'nr_red_parts', 'nr_green_parts', 'orig_part_of_new', 'new_part_of_orig',\n",
    "                               'one_edit_change', 'sentence_sim', 'diff_sim', \n",
    "                               'doubt_words_orig', 'doubt_words_new',\n",
    "                               'doubt_words_total',\n",
    "                               'negation_original',\n",
    "                               'negation_new', 'temporary',\n",
    "              'colors', 'days', 'currencies', 'months', 'winds', 'states', 'countries', 'cities', 'belgian', 'nationality',\n",
    "              'date_diff', 'person_diff', 'nr_full_sentences_original', 'nr_full_sentences_new',\n",
    "                               'entity_present_in_original', 'entity_present_in_new'                          \n",
    "                        ]\n",
    "\n",
    "if lang == 'bertje_full':\n",
    "    header_bertje_original = ['original_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_new = ['new_bertje_' + str(i) for i in range(0, 768)]\n",
    "    \n",
    "if lang == 'bertje_minimized':\n",
    "    header_bertje_minimized_original = ['original_minimized_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_minimized_new = ['new_minimized_bertje_' + str(i) for i in range(0, 768)]\n",
    "\n",
    "if lang == 'bertje_lemmatized':\n",
    "    header_bertje_lemmatized_original = ['original_lemmatized_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_lemmatized_new = ['new_lemmatized_bertje_' + str(i) for i in range(0, 768)]\n",
    "\n",
    "if lang == 'sbert_full':\n",
    "    header_sbert_original = ['original_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_new = ['new_sbert_' + str(i) for i in range(0, 512)]\n",
    "\n",
    "if lang == 'sbert_minimized':\n",
    "    header_sbert_minimized_original = ['original_minimized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_minimized_new = ['new_minimized_sbert_' + str(i) for i in range(0, 512)]\n",
    "\n",
    "if lang == 'sbert_lemmatized':\n",
    "    header_sbert_lemmatized_original = ['original_lemmatized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_lemmatized_new = ['new_lemmatized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    \n",
    "boolean_features = ['double_word', 'equal_after_subst', 'globally_equal_after_subst']\n",
    "text_array_lemmatized = ['original_lemmatized_minimized_changed_text', 'new_lemmatized_minimized_changed_text']\n",
    "text_array_minimized = ['original_minimized_changed_text', 'new_minimized_changed_text']\n",
    "text_array_changed = ['original_changed_text', 'new_changed_text']\n",
    "\n",
    "text_df = my_data[text_array_lemmatized].fillna('')\n",
    "text_minimized_df = my_data[text_array_minimized].fillna('')\n",
    "my_data = my_data.replace(np.inf, 0)\n",
    "\n",
    "#normalize all continuous variables before continuing\n",
    "normalized_continuous = (my_data[normalized_continuous_array] - my_data[normalized_continuous_array].min())/(my_data[normalized_continuous_array].max() - my_data[normalized_continuous_array].min() + 0.01)\n",
    "\n",
    "if lang == 'bertje_full':\n",
    "    normalized_bertje_original = (my_data[header_bertje_original] - my_data[header_bertje_original].min())/(my_data[header_bertje_original].max() - my_data[header_bertje_original].min() + 0.01)\n",
    "    normalized_bertje_new = (my_data[header_bertje_new] - my_data[header_bertje_new].min())/(my_data[header_bertje_new].max() - my_data[header_bertje_new].min() + 0.01)\n",
    "\n",
    "if lang == 'bertje_minimized':\n",
    "    normalized_bertje_minimized_original = (my_data[header_bertje_minimized_original] - my_data[header_bertje_minimized_original].min())/(my_data[header_bertje_minimized_original].max() - my_data[header_bertje_minimized_original].min() + 0.01)\n",
    "    normalized_bertje_minimized_new = (my_data[header_bertje_minimized_new] - my_data[header_bertje_minimized_new].min())/(my_data[header_bertje_minimized_new].max() - my_data[header_bertje_minimized_new].min() + 0.01)\n",
    "    \n",
    "if lang == 'bertje_lemmatized':\n",
    "    normalized_bertje_lemmatized_original = (my_data[header_bertje_lemmatized_original] - my_data[header_bertje_lemmatized_original].min())/(my_data[header_bertje_lemmatized_original].max() - my_data[header_bertje_lemmatized_original].min() + 0.01)\n",
    "    normalized_bertje_lemmatized_new = (my_data[header_bertje_lemmatized_new] - my_data[header_bertje_lemmatized_new].min())/(my_data[header_bertje_lemmatized_new].max() - my_data[header_bertje_lemmatized_new].min() + 0.01)\n",
    "\n",
    "if lang == 'sbert_full':\n",
    "    normalized_sbert_original = (my_data[header_sbert_original] - my_data[header_sbert_original].min())/(my_data[header_sbert_original].max() - my_data[header_sbert_original].min() + 0.01)\n",
    "    normalized_sbert_new = (my_data[header_sbert_new] - my_data[header_sbert_new].min())/(my_data[header_sbert_new].max() - my_data[header_sbert_new].min() + 0.01)\n",
    "\n",
    "if lang == 'sbert_minimized':\n",
    "    normalized_sbert_minimized_original = (my_data[header_sbert_minimized_original] - my_data[header_sbert_minimized_original].min())/(my_data[header_sbert_minimized_original].max() - my_data[header_sbert_minimized_original].min() + 0.01)\n",
    "    normalized_sbert_minimized_new = (my_data[header_sbert_minimized_new] - my_data[header_sbert_minimized_new].min())/(my_data[header_sbert_minimized_new].max() - my_data[header_sbert_minimized_new].min() + 0.01)    \n",
    "    \n",
    "if lang == 'sbert_lemmatized':\n",
    "    normalized_sbert_lemmatized_original = (my_data[header_sbert_lemmatized_original] - my_data[header_sbert_lemmatized_original].min())/(my_data[header_sbert_lemmatized_original].max() - my_data[header_sbert_lemmatized_original].min() + 0.01)\n",
    "    normalized_sbert_lemmatized_new = (my_data[header_sbert_lemmatized_new] - my_data[header_sbert_lemmatized_new].min())/(my_data[header_sbert_lemmatized_new].max() - my_data[header_sbert_lemmatized_new].min() + 0.01)\n",
    "    \n",
    "boolean = my_data[boolean_features]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = pd.DataFrame({'labels': le.fit_transform(my_data['type'])})\n",
    "\n",
    "test = pd.DataFrame({'test': my_data['test']})\n",
    "\n",
    "all_data = pd.concat([ohe_data, normalized_continuous, boolean, text_minimized_df, labels, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding vector embeddings in case of word2vec\n",
    "\n",
    "if lang == 'word2vec':\n",
    "    all_data[\"original_tokenized\"] = all_data.apply(lambda x: [word.lower() for word in word2vec_tokenizer(x['original_minimized_changed_text'])], axis=1)\n",
    "    all_data[\"new_tokenized\"] = all_data.apply(lambda x: [word.lower() for word in word2vec_tokenizer(x['new_minimized_changed_text'])], axis=1)\n",
    "\n",
    "    all_data[\"original_word2vec_array\"] = all_data.apply(lambda x: [word2vec_model[word] for word in x[\"original_tokenized\"] if word in word2vec_model], axis=1)\n",
    "    all_data[\"new_word2vec_array\"] = all_data.apply(lambda x: [word2vec_model[word] for word in x[\"new_tokenized\"] if word in word2vec_model], axis=1)\n",
    "\n",
    "    all_data[\"original_word2vec\"] = all_data.apply(lambda x: [float(sum(l))/len(l) for l in zip(*x[\"original_word2vec_array\"])], axis=1)\n",
    "    all_data[\"new_word2vec\"] = all_data.apply(lambda x: [float(sum(l))/len(l) for l in zip(*x[\"new_word2vec_array\"])], axis=1)\n",
    "\n",
    "    original_column_names = ['original_word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "    new_column_names = ['new_word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "    word2vec_column_names = ['word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "\n",
    "    word2vec_data_original = pd.DataFrame(all_data[\"original_word2vec\"].to_list(), columns=original_column_names)\n",
    "    word2vec_data_new = pd.DataFrame(all_data[\"new_word2vec\"].to_list(), columns=new_column_names)\n",
    "    word2vec_data = pd.DataFrame(word2vec_data_original - word2vec_data_new, columns=word2vec_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSE THE APPROPRIATE MODEL\n",
    "\n",
    "if lang == 'no text':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'tf-idf':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, text_df, boolean, labels, test], axis=1)\n",
    "    \n",
    "if lang == 'word2vec':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, word2vec_data_original, word2vec_data_new, boolean, labels, test], axis=1)\n",
    "    all_data[original_column_names] = all_data[original_column_names].fillna(0)\n",
    "    all_data[new_column_names] = all_data[new_column_names].fillna(0)\n",
    "    \n",
    "if lang == 'bertje_full':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_original, normalized_bertje_new, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'bertje_minimized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_minimized_original, normalized_bertje_minimized_new, boolean, labels, test], axis=1)    \n",
    "\n",
    "if lang == 'bertje_lemmatized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_lemmatized_original, normalized_bertje_lemmatized_new, boolean, labels, test], axis=1)\n",
    "    \n",
    "if lang == 'sbert_full':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_original, normalized_sbert_new, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'sbert_minimized':    \n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_minimized_original, normalized_sbert_minimized_new, boolean, labels, test], axis=1)    \n",
    "\n",
    "if lang == 'sbert_lemmatized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_lemmatized_original, normalized_sbert_lemmatized_new, boolean, labels, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up the training data (80%) and the test data (20%)\n",
    "train_data = all_data[all_data[\"test\"]==False].iloc[:, :-1]\n",
    "test_data = all_data[all_data[\"test\"]==True].iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY TO BE EXECUTED IN CASE OF TF-IDF\n",
    "\n",
    "#verify number of features needed for 95% threshold using LSA\n",
    "\n",
    "#transform textual data present in the atomic changes (in the attributes 'original_changed_text' and 'new_changed_text')\n",
    "#into TF-IDF features such that we have all initial features that would be used in the model\n",
    "\n",
    "if lang == 'tf-idf':\n",
    "    vectorizer_original = TfidfVectorizer()\n",
    "    vectorizer_new = TfidfVectorizer()\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        [('tfidf_original', vectorizer_original, 'original_lemmatized_minimized_changed_text'), \n",
    "        ('tfidf_new', vectorizer_new, 'new_lemmatized_minimized_changed_text')],\n",
    "        remainder='passthrough')\n",
    "\n",
    "    temp_train_data = column_transformer.fit_transform(train_data)\n",
    "\n",
    "    truncatedsvd = TruncatedSVD(n_components=1850)\n",
    "    truncatedsvd.fit(temp_train_data)\n",
    "\n",
    "    print(truncatedsvd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define f2 scorer\n",
    "def fbeta_score(y_true, y_pred):\n",
    "    return metrics.fbeta_score(y_true, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the training data into five different folds in order to apply stratified k-fold cross validation\n",
    "#for the final execution of the best model\n",
    "train_data[\"kfold\"] = -1\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_, v_) in enumerate(kf.split(X = train_data, y=train_data['labels'].values)):\n",
    "    train_data.loc[v_, 'kfold'] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that implements grid search for hyperparameter optimization by selecting the optimization algorithm\n",
    "#and parameters accordingly\n",
    "def grid(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    #Grid Search Model\n",
    "    if alg == 'decision tree':\n",
    "        clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "        \n",
    "        param_grid = {\"classify__criterion\": ['entropy', 'gini'], \n",
    "        \"classify__max_depth\": [2,4,6,8,10,12, 14, 16, 18, 20, 22, 24, 26, 28, 30]}\n",
    "    \n",
    "    if alg == 'logistic regression':\n",
    "        clf = linear_model.LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "        \n",
    "        param_grid = {\"classify__C\":[0.01, 0.1, 1.0], \"classify__penalty\":[\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"classify__solver\": ['newton-cg', \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}\n",
    "    \n",
    "    if alg == 'support vector machine':\n",
    "        clf = LinearSVC(class_weight=\"balanced\", random_state=0)\n",
    "        \n",
    "        param_grid = {\"classify__loss\": ['hinge', 'squared_hinge'],\n",
    "        \"classify__C\":[ 0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \"classify__penalty\":[\"l2\"]}\n",
    "    \n",
    "    sampling_strategy_o = 0.40\n",
    "    \n",
    "    if lang == 'tf-idf':\n",
    "        pipe = imb_pipeline([\n",
    "                    ('tfidf', column_transformer),\n",
    "                    ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                    ('classify', clf)\n",
    "            ])\n",
    "        \n",
    "    else:\n",
    "        pipe = imb_pipeline([\n",
    "                    ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                    ('classify', clf)\n",
    "        ])\n",
    "\n",
    "    \n",
    "    scorer = metrics.make_scorer(fbeta_score, greater_is_better=True, needs_threshold=False)\n",
    "\n",
    "    grid_model = model_selection.GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    refit=True,\n",
    "    verbose=10,\n",
    "    cv=5)\n",
    "    \n",
    "    grid_model.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best score: \" + str(grid_model.best_score_))\n",
    "    print(\"Best parameter set: \")\n",
    "    best_parameters = grid_model.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    best_model = grid_model.best_estimator_\n",
    "    best_model.fit(x_train, y_train)\n",
    "    preds = best_model.predict(x_test)\n",
    "    \n",
    "    score = metrics.fbeta_score(y_test, preds, beta=2)\n",
    "    print(\"Test score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV 1/5; 1/45] START classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 1/5; 1/45] END classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.1s\n",
      "[CV 2/5; 1/45] START classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 2/5; 1/45] END classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 3/5; 1/45] START classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 3/5; 1/45] END classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 4/5; 1/45] START classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 4/5; 1/45] END classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   0.9s\n",
      "[CV 5/5; 1/45] START classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 5/5; 1/45] END classify__C=0.01, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 1/5; 2/45] START classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 1/5; 2/45] END classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   0.9s\n",
      "[CV 2/5; 2/45] START classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 2/5; 2/45] END classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.1s\n",
      "[CV 3/5; 2/45] START classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 3/5; 2/45] END classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.1s\n",
      "[CV 4/5; 2/45] START classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 4/5; 2/45] END classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   0.9s\n",
      "[CV 5/5; 2/45] START classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 5/5; 2/45] END classify__C=0.01, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   0.9s\n",
      "[CV 1/5; 3/45] START classify__C=0.01, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 1/5; 3/45] END classify__C=0.01, classify__penalty=l1, classify__solver=liblinear;, score=0.747 total time=   3.6s\n",
      "[CV 2/5; 3/45] START classify__C=0.01, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 2/5; 3/45] END classify__C=0.01, classify__penalty=l1, classify__solver=liblinear;, score=0.736 total time=   3.4s\n",
      "[CV 3/5; 3/45] START classify__C=0.01, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 3/5; 3/45] END classify__C=0.01, classify__penalty=l1, classify__solver=liblinear;, score=0.749 total time=   3.4s\n",
      "[CV 4/5; 3/45] START classify__C=0.01, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 4/5; 3/45] END classify__C=0.01, classify__penalty=l1, classify__solver=liblinear;, score=0.739 total time=   3.3s\n",
      "[CV 5/5; 3/45] START classify__C=0.01, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 5/5; 3/45] END classify__C=0.01, classify__penalty=l1, classify__solver=liblinear;, score=0.746 total time=   3.3s\n",
      "[CV 1/5; 4/45] START classify__C=0.01, classify__penalty=l1, classify__solver=sag\n",
      "[CV 1/5; 4/45] END classify__C=0.01, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.1s\n",
      "[CV 2/5; 4/45] START classify__C=0.01, classify__penalty=l1, classify__solver=sag\n",
      "[CV 2/5; 4/45] END classify__C=0.01, classify__penalty=l1, classify__solver=sag;, score=nan total time=   0.9s\n",
      "[CV 3/5; 4/45] START classify__C=0.01, classify__penalty=l1, classify__solver=sag\n",
      "[CV 3/5; 4/45] END classify__C=0.01, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.0s\n",
      "[CV 4/5; 4/45] START classify__C=0.01, classify__penalty=l1, classify__solver=sag\n",
      "[CV 4/5; 4/45] END classify__C=0.01, classify__penalty=l1, classify__solver=sag;, score=nan total time=   0.9s\n",
      "[CV 5/5; 4/45] START classify__C=0.01, classify__penalty=l1, classify__solver=sag\n",
      "[CV 5/5; 4/45] END classify__C=0.01, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.2s\n",
      "[CV 1/5; 5/45] START classify__C=0.01, classify__penalty=l1, classify__solver=saga\n",
      "[CV 1/5; 5/45] END classify__C=0.01, classify__penalty=l1, classify__solver=saga;, score=0.744 total time= 1.7min\n",
      "[CV 2/5; 5/45] START classify__C=0.01, classify__penalty=l1, classify__solver=saga\n",
      "[CV 2/5; 5/45] END classify__C=0.01, classify__penalty=l1, classify__solver=saga;, score=0.737 total time= 1.7min\n",
      "[CV 3/5; 5/45] START classify__C=0.01, classify__penalty=l1, classify__solver=saga\n",
      "[CV 3/5; 5/45] END classify__C=0.01, classify__penalty=l1, classify__solver=saga;, score=0.744 total time= 1.6min\n",
      "[CV 4/5; 5/45] START classify__C=0.01, classify__penalty=l1, classify__solver=saga\n",
      "[CV 4/5; 5/45] END classify__C=0.01, classify__penalty=l1, classify__solver=saga;, score=0.747 total time= 1.9min\n",
      "[CV 5/5; 5/45] START classify__C=0.01, classify__penalty=l1, classify__solver=saga\n",
      "[CV 5/5; 5/45] END classify__C=0.01, classify__penalty=l1, classify__solver=saga;, score=0.754 total time= 1.9min\n",
      "[CV 1/5; 6/45] START classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 1/5; 6/45] END classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg;, score=0.777 total time=   7.6s\n",
      "[CV 2/5; 6/45] START classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 2/5; 6/45] END classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg;, score=0.786 total time=   7.1s\n",
      "[CV 3/5; 6/45] START classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 3/5; 6/45] END classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg;, score=0.794 total time=   6.1s\n",
      "[CV 4/5; 6/45] START classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 4/5; 6/45] END classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg;, score=0.795 total time=   6.6s\n",
      "[CV 5/5; 6/45] START classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 5/5; 6/45] END classify__C=0.01, classify__penalty=l2, classify__solver=newton-cg;, score=0.798 total time=   6.7s\n",
      "[CV 1/5; 7/45] START classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 1/5; 7/45] END classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs;, score=0.777 total time=   2.6s\n",
      "[CV 2/5; 7/45] START classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 2/5; 7/45] END classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs;, score=0.786 total time=   3.5s\n",
      "[CV 3/5; 7/45] START classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 3/5; 7/45] END classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs;, score=0.794 total time=   3.1s\n",
      "[CV 4/5; 7/45] START classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 4/5; 7/45] END classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs;, score=0.795 total time=   3.6s\n",
      "[CV 5/5; 7/45] START classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 5/5; 7/45] END classify__C=0.01, classify__penalty=l2, classify__solver=lbfgs;, score=0.798 total time=   2.5s\n",
      "[CV 1/5; 8/45] START classify__C=0.01, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 1/5; 8/45] END classify__C=0.01, classify__penalty=l2, classify__solver=liblinear;, score=0.777 total time=   5.2s\n",
      "[CV 2/5; 8/45] START classify__C=0.01, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 2/5; 8/45] END classify__C=0.01, classify__penalty=l2, classify__solver=liblinear;, score=0.786 total time=   5.3s\n",
      "[CV 3/5; 8/45] START classify__C=0.01, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 3/5; 8/45] END classify__C=0.01, classify__penalty=l2, classify__solver=liblinear;, score=0.794 total time=   5.3s\n",
      "[CV 4/5; 8/45] START classify__C=0.01, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 4/5; 8/45] END classify__C=0.01, classify__penalty=l2, classify__solver=liblinear;, score=0.795 total time=   5.1s\n",
      "[CV 5/5; 8/45] START classify__C=0.01, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 5/5; 8/45] END classify__C=0.01, classify__penalty=l2, classify__solver=liblinear;, score=0.797 total time=   5.1s\n",
      "[CV 1/5; 9/45] START classify__C=0.01, classify__penalty=l2, classify__solver=sag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/45] END classify__C=0.01, classify__penalty=l2, classify__solver=sag;, score=0.777 total time=  10.3s\n",
      "[CV 2/5; 9/45] START classify__C=0.01, classify__penalty=l2, classify__solver=sag\n",
      "[CV 2/5; 9/45] END classify__C=0.01, classify__penalty=l2, classify__solver=sag;, score=0.786 total time=   9.5s\n",
      "[CV 3/5; 9/45] START classify__C=0.01, classify__penalty=l2, classify__solver=sag\n",
      "[CV 3/5; 9/45] END classify__C=0.01, classify__penalty=l2, classify__solver=sag;, score=0.794 total time=   9.4s\n",
      "[CV 4/5; 9/45] START classify__C=0.01, classify__penalty=l2, classify__solver=sag\n",
      "[CV 4/5; 9/45] END classify__C=0.01, classify__penalty=l2, classify__solver=sag;, score=0.795 total time=   9.3s\n",
      "[CV 5/5; 9/45] START classify__C=0.01, classify__penalty=l2, classify__solver=sag\n",
      "[CV 5/5; 9/45] END classify__C=0.01, classify__penalty=l2, classify__solver=sag;, score=0.797 total time=   9.6s\n",
      "[CV 1/5; 10/45] START classify__C=0.01, classify__penalty=l2, classify__solver=saga\n",
      "[CV 1/5; 10/45] END classify__C=0.01, classify__penalty=l2, classify__solver=saga;, score=0.777 total time=   6.6s\n",
      "[CV 2/5; 10/45] START classify__C=0.01, classify__penalty=l2, classify__solver=saga\n",
      "[CV 2/5; 10/45] END classify__C=0.01, classify__penalty=l2, classify__solver=saga;, score=0.786 total time=   6.9s\n",
      "[CV 3/5; 10/45] START classify__C=0.01, classify__penalty=l2, classify__solver=saga\n",
      "[CV 3/5; 10/45] END classify__C=0.01, classify__penalty=l2, classify__solver=saga;, score=0.794 total time=   6.8s\n",
      "[CV 4/5; 10/45] START classify__C=0.01, classify__penalty=l2, classify__solver=saga\n",
      "[CV 4/5; 10/45] END classify__C=0.01, classify__penalty=l2, classify__solver=saga;, score=0.795 total time=   7.1s\n",
      "[CV 5/5; 10/45] START classify__C=0.01, classify__penalty=l2, classify__solver=saga\n",
      "[CV 5/5; 10/45] END classify__C=0.01, classify__penalty=l2, classify__solver=saga;, score=0.798 total time=   6.8s\n",
      "[CV 1/5; 11/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 1/5; 11/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   0.9s\n",
      "[CV 2/5; 11/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 2/5; 11/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   0.9s\n",
      "[CV 3/5; 11/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 3/5; 11/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 4/5; 11/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 4/5; 11/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   0.9s\n",
      "[CV 5/5; 11/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 5/5; 11/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 1/5; 12/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 1/5; 12/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   0.9s\n",
      "[CV 2/5; 12/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 2/5; 12/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.0s\n",
      "[CV 3/5; 12/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 3/5; 12/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   0.9s\n",
      "[CV 4/5; 12/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 4/5; 12/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.0s\n",
      "[CV 5/5; 12/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 5/5; 12/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.0s\n",
      "[CV 1/5; 13/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 1/5; 13/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   0.9s\n",
      "[CV 2/5; 13/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 2/5; 13/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.0s\n",
      "[CV 3/5; 13/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 3/5; 13/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.0s\n",
      "[CV 4/5; 13/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 4/5; 13/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   0.9s\n",
      "[CV 5/5; 13/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 5/5; 13/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   0.9s\n",
      "[CV 1/5; 14/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 1/5; 14/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.0s\n",
      "[CV 2/5; 14/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 2/5; 14/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.0s\n",
      "[CV 3/5; 14/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 3/5; 14/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   0.9s\n",
      "[CV 4/5; 14/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 4/5; 14/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.0s\n",
      "[CV 5/5; 14/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 5/5; 14/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   0.9s\n",
      "[CV 1/5; 15/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 1/5; 15/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   0.8s\n",
      "[CV 2/5; 15/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 2/5; 15/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.0s\n",
      "[CV 3/5; 15/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 3/5; 15/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.0s\n",
      "[CV 4/5; 15/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 4/5; 15/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   0.9s\n",
      "[CV 5/5; 15/45] START classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 5/5; 15/45] END classify__C=0.01, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   0.9s\n",
      "[CV 1/5; 16/45] START classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 1/5; 16/45] END classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 2/5; 16/45] START classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 2/5; 16/45] END classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 3/5; 16/45] START classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 3/5; 16/45] END classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 4/5; 16/45] START classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 4/5; 16/45] END classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 5/5; 16/45] START classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 16/45] END classify__C=0.1, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.7s\n",
      "[CV 1/5; 17/45] START classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 1/5; 17/45] END classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 2/5; 17/45] START classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 2/5; 17/45] END classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.0s\n",
      "[CV 3/5; 17/45] START classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 3/5; 17/45] END classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.0s\n",
      "[CV 4/5; 17/45] START classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 4/5; 17/45] END classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   0.9s\n",
      "[CV 5/5; 17/45] START classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 5/5; 17/45] END classify__C=0.1, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   0.9s\n",
      "[CV 1/5; 18/45] START classify__C=0.1, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 1/5; 18/45] END classify__C=0.1, classify__penalty=l1, classify__solver=liblinear;, score=0.792 total time=   8.0s\n",
      "[CV 2/5; 18/45] START classify__C=0.1, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 2/5; 18/45] END classify__C=0.1, classify__penalty=l1, classify__solver=liblinear;, score=0.798 total time=   7.3s\n",
      "[CV 3/5; 18/45] START classify__C=0.1, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 3/5; 18/45] END classify__C=0.1, classify__penalty=l1, classify__solver=liblinear;, score=0.816 total time=   7.3s\n",
      "[CV 4/5; 18/45] START classify__C=0.1, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 4/5; 18/45] END classify__C=0.1, classify__penalty=l1, classify__solver=liblinear;, score=0.786 total time=   7.4s\n",
      "[CV 5/5; 18/45] START classify__C=0.1, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 5/5; 18/45] END classify__C=0.1, classify__penalty=l1, classify__solver=liblinear;, score=0.805 total time=   7.8s\n",
      "[CV 1/5; 19/45] START classify__C=0.1, classify__penalty=l1, classify__solver=sag\n",
      "[CV 1/5; 19/45] END classify__C=0.1, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.0s\n",
      "[CV 2/5; 19/45] START classify__C=0.1, classify__penalty=l1, classify__solver=sag\n",
      "[CV 2/5; 19/45] END classify__C=0.1, classify__penalty=l1, classify__solver=sag;, score=nan total time=   0.9s\n",
      "[CV 3/5; 19/45] START classify__C=0.1, classify__penalty=l1, classify__solver=sag\n",
      "[CV 3/5; 19/45] END classify__C=0.1, classify__penalty=l1, classify__solver=sag;, score=nan total time=   0.9s\n",
      "[CV 4/5; 19/45] START classify__C=0.1, classify__penalty=l1, classify__solver=sag\n",
      "[CV 4/5; 19/45] END classify__C=0.1, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.1s\n",
      "[CV 5/5; 19/45] START classify__C=0.1, classify__penalty=l1, classify__solver=sag\n",
      "[CV 5/5; 19/45] END classify__C=0.1, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.0s\n",
      "[CV 1/5; 20/45] START classify__C=0.1, classify__penalty=l1, classify__solver=saga\n",
      "[CV 1/5; 20/45] END classify__C=0.1, classify__penalty=l1, classify__solver=saga;, score=0.793 total time= 3.4min\n",
      "[CV 2/5; 20/45] START classify__C=0.1, classify__penalty=l1, classify__solver=saga\n",
      "[CV 2/5; 20/45] END classify__C=0.1, classify__penalty=l1, classify__solver=saga;, score=0.798 total time= 4.1min\n",
      "[CV 3/5; 20/45] START classify__C=0.1, classify__penalty=l1, classify__solver=saga\n",
      "[CV 3/5; 20/45] END classify__C=0.1, classify__penalty=l1, classify__solver=saga;, score=0.815 total time= 4.4min\n",
      "[CV 4/5; 20/45] START classify__C=0.1, classify__penalty=l1, classify__solver=saga\n",
      "[CV 4/5; 20/45] END classify__C=0.1, classify__penalty=l1, classify__solver=saga;, score=0.786 total time= 6.2min\n",
      "[CV 5/5; 20/45] START classify__C=0.1, classify__penalty=l1, classify__solver=saga\n",
      "[CV 5/5; 20/45] END classify__C=0.1, classify__penalty=l1, classify__solver=saga;, score=0.805 total time= 6.6min\n",
      "[CV 1/5; 21/45] START classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 1/5; 21/45] END classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg;, score=0.788 total time=  14.5s\n",
      "[CV 2/5; 21/45] START classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 2/5; 21/45] END classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg;, score=0.793 total time=  14.3s\n",
      "[CV 3/5; 21/45] START classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 3/5; 21/45] END classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg;, score=0.806 total time=  15.0s\n",
      "[CV 4/5; 21/45] START classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 4/5; 21/45] END classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg;, score=0.786 total time=  12.6s\n",
      "[CV 5/5; 21/45] START classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 5/5; 21/45] END classify__C=0.1, classify__penalty=l2, classify__solver=newton-cg;, score=0.808 total time=  11.9s\n",
      "[CV 1/5; 22/45] START classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 1/5; 22/45] END classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs;, score=0.788 total time=   8.8s\n",
      "[CV 2/5; 22/45] START classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 2/5; 22/45] END classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs;, score=0.793 total time=   9.1s\n",
      "[CV 3/5; 22/45] START classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 3/5; 22/45] END classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs;, score=0.806 total time=   6.4s\n",
      "[CV 4/5; 22/45] START classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 4/5; 22/45] END classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs;, score=0.786 total time=   8.8s\n",
      "[CV 5/5; 22/45] START classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 5/5; 22/45] END classify__C=0.1, classify__penalty=l2, classify__solver=lbfgs;, score=0.808 total time=   8.3s\n",
      "[CV 1/5; 23/45] START classify__C=0.1, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 1/5; 23/45] END classify__C=0.1, classify__penalty=l2, classify__solver=liblinear;, score=0.788 total time=  10.8s\n",
      "[CV 2/5; 23/45] START classify__C=0.1, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 2/5; 23/45] END classify__C=0.1, classify__penalty=l2, classify__solver=liblinear;, score=0.793 total time=  10.6s\n",
      "[CV 3/5; 23/45] START classify__C=0.1, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 3/5; 23/45] END classify__C=0.1, classify__penalty=l2, classify__solver=liblinear;, score=0.806 total time=  10.7s\n",
      "[CV 4/5; 23/45] START classify__C=0.1, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 4/5; 23/45] END classify__C=0.1, classify__penalty=l2, classify__solver=liblinear;, score=0.786 total time=  10.6s\n",
      "[CV 5/5; 23/45] START classify__C=0.1, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 5/5; 23/45] END classify__C=0.1, classify__penalty=l2, classify__solver=liblinear;, score=0.808 total time=  10.7s\n",
      "[CV 1/5; 24/45] START classify__C=0.1, classify__penalty=l2, classify__solver=sag\n",
      "[CV 1/5; 24/45] END classify__C=0.1, classify__penalty=l2, classify__solver=sag;, score=0.788 total time=  18.3s\n",
      "[CV 2/5; 24/45] START classify__C=0.1, classify__penalty=l2, classify__solver=sag\n",
      "[CV 2/5; 24/45] END classify__C=0.1, classify__penalty=l2, classify__solver=sag;, score=0.793 total time=  17.8s\n",
      "[CV 3/5; 24/45] START classify__C=0.1, classify__penalty=l2, classify__solver=sag\n",
      "[CV 3/5; 24/45] END classify__C=0.1, classify__penalty=l2, classify__solver=sag;, score=0.806 total time=  18.0s\n",
      "[CV 4/5; 24/45] START classify__C=0.1, classify__penalty=l2, classify__solver=sag\n",
      "[CV 4/5; 24/45] END classify__C=0.1, classify__penalty=l2, classify__solver=sag;, score=0.786 total time=  17.1s\n",
      "[CV 5/5; 24/45] START classify__C=0.1, classify__penalty=l2, classify__solver=sag\n",
      "[CV 5/5; 24/45] END classify__C=0.1, classify__penalty=l2, classify__solver=sag;, score=0.808 total time=  16.6s\n",
      "[CV 1/5; 25/45] START classify__C=0.1, classify__penalty=l2, classify__solver=saga\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 25/45] END classify__C=0.1, classify__penalty=l2, classify__solver=saga;, score=0.788 total time=  31.2s\n",
      "[CV 2/5; 25/45] START classify__C=0.1, classify__penalty=l2, classify__solver=saga\n",
      "[CV 2/5; 25/45] END classify__C=0.1, classify__penalty=l2, classify__solver=saga;, score=0.793 total time=  31.0s\n",
      "[CV 3/5; 25/45] START classify__C=0.1, classify__penalty=l2, classify__solver=saga\n",
      "[CV 3/5; 25/45] END classify__C=0.1, classify__penalty=l2, classify__solver=saga;, score=0.806 total time=  31.5s\n",
      "[CV 4/5; 25/45] START classify__C=0.1, classify__penalty=l2, classify__solver=saga\n",
      "[CV 4/5; 25/45] END classify__C=0.1, classify__penalty=l2, classify__solver=saga;, score=0.786 total time=  32.7s\n",
      "[CV 5/5; 25/45] START classify__C=0.1, classify__penalty=l2, classify__solver=saga\n",
      "[CV 5/5; 25/45] END classify__C=0.1, classify__penalty=l2, classify__solver=saga;, score=0.808 total time=  30.3s\n",
      "[CV 1/5; 26/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 1/5; 26/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.3s\n",
      "[CV 2/5; 26/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 2/5; 26/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.4s\n",
      "[CV 3/5; 26/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 3/5; 26/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.3s\n",
      "[CV 4/5; 26/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 4/5; 26/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.1s\n",
      "[CV 5/5; 26/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 5/5; 26/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.2s\n",
      "[CV 1/5; 27/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 1/5; 27/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 2/5; 27/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 2/5; 27/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.2s\n",
      "[CV 3/5; 27/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 3/5; 27/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.2s\n",
      "[CV 4/5; 27/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 4/5; 27/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 5/5; 27/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 5/5; 27/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.2s\n",
      "[CV 1/5; 28/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 1/5; 28/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.3s\n",
      "[CV 2/5; 28/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 2/5; 28/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.3s\n",
      "[CV 3/5; 28/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 3/5; 28/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.1s\n",
      "[CV 4/5; 28/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 4/5; 28/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.2s\n",
      "[CV 5/5; 28/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 5/5; 28/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.2s\n",
      "[CV 1/5; 29/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 1/5; 29/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.2s\n",
      "[CV 2/5; 29/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 2/5; 29/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.5s\n",
      "[CV 3/5; 29/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 3/5; 29/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.5s\n",
      "[CV 4/5; 29/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 4/5; 29/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.4s\n",
      "[CV 5/5; 29/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 5/5; 29/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.7s\n",
      "[CV 1/5; 30/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 1/5; 30/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.5s\n",
      "[CV 2/5; 30/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 2/5; 30/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.4s\n",
      "[CV 3/5; 30/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 3/5; 30/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.4s\n",
      "[CV 4/5; 30/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 4/5; 30/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.3s\n",
      "[CV 5/5; 30/45] START classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 5/5; 30/45] END classify__C=0.1, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.5s\n",
      "[CV 1/5; 31/45] START classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 1/5; 31/45] END classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.9s\n",
      "[CV 2/5; 31/45] START classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 2/5; 31/45] END classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.7s\n",
      "[CV 3/5; 31/45] START classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 3/5; 31/45] END classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.3s\n",
      "[CV 4/5; 31/45] START classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 4/5; 31/45] END classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.2s\n",
      "[CV 5/5; 31/45] START classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg\n",
      "[CV 5/5; 31/45] END classify__C=1.0, classify__penalty=l1, classify__solver=newton-cg;, score=nan total time=   1.3s\n",
      "[CV 1/5; 32/45] START classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 1/5; 32/45] END classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.1s\n",
      "[CV 2/5; 32/45] START classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 2/5; 32/45] END classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.2s\n",
      "[CV 3/5; 32/45] START classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 3/5; 32/45] END classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 4/5; 32/45] START classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 4/5; 32/45] END classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.1s\n",
      "[CV 5/5; 32/45] START classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs\n",
      "[CV 5/5; 32/45] END classify__C=1.0, classify__penalty=l1, classify__solver=lbfgs;, score=nan total time=   1.2s\n",
      "[CV 1/5; 33/45] START classify__C=1.0, classify__penalty=l1, classify__solver=liblinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 33/45] END classify__C=1.0, classify__penalty=l1, classify__solver=liblinear;, score=0.774 total time= 2.1min\n",
      "[CV 2/5; 33/45] START classify__C=1.0, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 2/5; 33/45] END classify__C=1.0, classify__penalty=l1, classify__solver=liblinear;, score=0.773 total time= 2.1min\n",
      "[CV 3/5; 33/45] START classify__C=1.0, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 3/5; 33/45] END classify__C=1.0, classify__penalty=l1, classify__solver=liblinear;, score=0.789 total time= 2.2min\n",
      "[CV 4/5; 33/45] START classify__C=1.0, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 4/5; 33/45] END classify__C=1.0, classify__penalty=l1, classify__solver=liblinear;, score=0.751 total time= 2.4min\n",
      "[CV 5/5; 33/45] START classify__C=1.0, classify__penalty=l1, classify__solver=liblinear\n",
      "[CV 5/5; 33/45] END classify__C=1.0, classify__penalty=l1, classify__solver=liblinear;, score=0.790 total time= 2.0min\n",
      "[CV 1/5; 34/45] START classify__C=1.0, classify__penalty=l1, classify__solver=sag\n",
      "[CV 1/5; 34/45] END classify__C=1.0, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.0s\n",
      "[CV 2/5; 34/45] START classify__C=1.0, classify__penalty=l1, classify__solver=sag\n",
      "[CV 2/5; 34/45] END classify__C=1.0, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.1s\n",
      "[CV 3/5; 34/45] START classify__C=1.0, classify__penalty=l1, classify__solver=sag\n",
      "[CV 3/5; 34/45] END classify__C=1.0, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.2s\n",
      "[CV 4/5; 34/45] START classify__C=1.0, classify__penalty=l1, classify__solver=sag\n",
      "[CV 4/5; 34/45] END classify__C=1.0, classify__penalty=l1, classify__solver=sag;, score=nan total time=   0.9s\n",
      "[CV 5/5; 34/45] START classify__C=1.0, classify__penalty=l1, classify__solver=sag\n",
      "[CV 5/5; 34/45] END classify__C=1.0, classify__penalty=l1, classify__solver=sag;, score=nan total time=   1.0s\n",
      "[CV 1/5; 35/45] START classify__C=1.0, classify__penalty=l1, classify__solver=saga\n",
      "[CV 1/5; 35/45] END classify__C=1.0, classify__penalty=l1, classify__solver=saga;, score=0.778 total time=10.3min\n",
      "[CV 2/5; 35/45] START classify__C=1.0, classify__penalty=l1, classify__solver=saga\n",
      "[CV 2/5; 35/45] END classify__C=1.0, classify__penalty=l1, classify__solver=saga;, score=0.772 total time=10.6min\n",
      "[CV 3/5; 35/45] START classify__C=1.0, classify__penalty=l1, classify__solver=saga\n",
      "[CV 3/5; 35/45] END classify__C=1.0, classify__penalty=l1, classify__solver=saga;, score=0.786 total time=10.9min\n",
      "[CV 4/5; 35/45] START classify__C=1.0, classify__penalty=l1, classify__solver=saga\n",
      "[CV 4/5; 35/45] END classify__C=1.0, classify__penalty=l1, classify__solver=saga;, score=0.751 total time=10.9min\n",
      "[CV 5/5; 35/45] START classify__C=1.0, classify__penalty=l1, classify__solver=saga\n",
      "[CV 5/5; 35/45] END classify__C=1.0, classify__penalty=l1, classify__solver=saga;, score=0.790 total time=10.7min\n",
      "[CV 1/5; 36/45] START classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 1/5; 36/45] END classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg;, score=0.769 total time=  19.5s\n",
      "[CV 2/5; 36/45] START classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 2/5; 36/45] END classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg;, score=0.768 total time=  16.9s\n",
      "[CV 3/5; 36/45] START classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 3/5; 36/45] END classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg;, score=0.783 total time=  19.3s\n",
      "[CV 4/5; 36/45] START classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 4/5; 36/45] END classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg;, score=0.749 total time=  18.1s\n",
      "[CV 5/5; 36/45] START classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg\n",
      "[CV 5/5; 36/45] END classify__C=1.0, classify__penalty=l2, classify__solver=newton-cg;, score=0.793 total time=  18.9s\n",
      "[CV 1/5; 37/45] START classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 1/5; 37/45] END classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs;, score=0.769 total time=  17.6s\n",
      "[CV 2/5; 37/45] START classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 2/5; 37/45] END classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs;, score=0.768 total time=  18.6s\n",
      "[CV 3/5; 37/45] START classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 3/5; 37/45] END classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs;, score=0.782 total time=  15.5s\n",
      "[CV 4/5; 37/45] START classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 4/5; 37/45] END classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs;, score=0.749 total time=  17.0s\n",
      "[CV 5/5; 37/45] START classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs\n",
      "[CV 5/5; 37/45] END classify__C=1.0, classify__penalty=l2, classify__solver=lbfgs;, score=0.793 total time=  18.8s\n",
      "[CV 1/5; 38/45] START classify__C=1.0, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 1/5; 38/45] END classify__C=1.0, classify__penalty=l2, classify__solver=liblinear;, score=0.769 total time=  15.5s\n",
      "[CV 2/5; 38/45] START classify__C=1.0, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 2/5; 38/45] END classify__C=1.0, classify__penalty=l2, classify__solver=liblinear;, score=0.768 total time=  16.9s\n",
      "[CV 3/5; 38/45] START classify__C=1.0, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 3/5; 38/45] END classify__C=1.0, classify__penalty=l2, classify__solver=liblinear;, score=0.783 total time=  18.0s\n",
      "[CV 4/5; 38/45] START classify__C=1.0, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 4/5; 38/45] END classify__C=1.0, classify__penalty=l2, classify__solver=liblinear;, score=0.749 total time=  16.0s\n",
      "[CV 5/5; 38/45] START classify__C=1.0, classify__penalty=l2, classify__solver=liblinear\n",
      "[CV 5/5; 38/45] END classify__C=1.0, classify__penalty=l2, classify__solver=liblinear;, score=0.793 total time=  14.4s\n",
      "[CV 1/5; 39/45] START classify__C=1.0, classify__penalty=l2, classify__solver=sag\n",
      "[CV 1/5; 39/45] END classify__C=1.0, classify__penalty=l2, classify__solver=sag;, score=0.770 total time= 1.4min\n",
      "[CV 2/5; 39/45] START classify__C=1.0, classify__penalty=l2, classify__solver=sag\n",
      "[CV 2/5; 39/45] END classify__C=1.0, classify__penalty=l2, classify__solver=sag;, score=0.769 total time= 1.6min\n",
      "[CV 3/5; 39/45] START classify__C=1.0, classify__penalty=l2, classify__solver=sag\n",
      "[CV 3/5; 39/45] END classify__C=1.0, classify__penalty=l2, classify__solver=sag;, score=0.782 total time= 1.7min\n",
      "[CV 4/5; 39/45] START classify__C=1.0, classify__penalty=l2, classify__solver=sag\n",
      "[CV 4/5; 39/45] END classify__C=1.0, classify__penalty=l2, classify__solver=sag;, score=0.747 total time= 1.8min\n",
      "[CV 5/5; 39/45] START classify__C=1.0, classify__penalty=l2, classify__solver=sag\n",
      "[CV 5/5; 39/45] END classify__C=1.0, classify__penalty=l2, classify__solver=sag;, score=0.793 total time= 1.7min\n",
      "[CV 1/5; 40/45] START classify__C=1.0, classify__penalty=l2, classify__solver=saga\n",
      "[CV 1/5; 40/45] END classify__C=1.0, classify__penalty=l2, classify__solver=saga;, score=0.770 total time= 2.8min\n",
      "[CV 2/5; 40/45] START classify__C=1.0, classify__penalty=l2, classify__solver=saga\n",
      "[CV 2/5; 40/45] END classify__C=1.0, classify__penalty=l2, classify__solver=saga;, score=0.770 total time= 3.0min\n",
      "[CV 3/5; 40/45] START classify__C=1.0, classify__penalty=l2, classify__solver=saga\n",
      "[CV 3/5; 40/45] END classify__C=1.0, classify__penalty=l2, classify__solver=saga;, score=0.783 total time= 2.8min\n",
      "[CV 4/5; 40/45] START classify__C=1.0, classify__penalty=l2, classify__solver=saga\n",
      "[CV 4/5; 40/45] END classify__C=1.0, classify__penalty=l2, classify__solver=saga;, score=0.748 total time= 2.8min\n",
      "[CV 5/5; 40/45] START classify__C=1.0, classify__penalty=l2, classify__solver=saga\n",
      "[CV 5/5; 40/45] END classify__C=1.0, classify__penalty=l2, classify__solver=saga;, score=0.792 total time= 2.8min\n",
      "[CV 1/5; 41/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 1/5; 41/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.3s\n",
      "[CV 2/5; 41/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 41/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.2s\n",
      "[CV 3/5; 41/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 3/5; 41/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.3s\n",
      "[CV 4/5; 41/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 4/5; 41/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.1s\n",
      "[CV 5/5; 41/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg\n",
      "[CV 5/5; 41/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=newton-cg;, score=nan total time=   1.3s\n",
      "[CV 1/5; 42/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 1/5; 42/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.3s\n",
      "[CV 2/5; 42/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 2/5; 42/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.2s\n",
      "[CV 3/5; 42/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 3/5; 42/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.1s\n",
      "[CV 4/5; 42/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 4/5; 42/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.2s\n",
      "[CV 5/5; 42/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs\n",
      "[CV 5/5; 42/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=lbfgs;, score=nan total time=   1.1s\n",
      "[CV 1/5; 43/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 1/5; 43/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.1s\n",
      "[CV 2/5; 43/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 2/5; 43/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.3s\n",
      "[CV 3/5; 43/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 3/5; 43/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.3s\n",
      "[CV 4/5; 43/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 4/5; 43/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.1s\n",
      "[CV 5/5; 43/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear\n",
      "[CV 5/5; 43/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=liblinear;, score=nan total time=   1.1s\n",
      "[CV 1/5; 44/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 1/5; 44/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.2s\n",
      "[CV 2/5; 44/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 2/5; 44/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.4s\n",
      "[CV 3/5; 44/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 3/5; 44/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.1s\n",
      "[CV 4/5; 44/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 4/5; 44/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.4s\n",
      "[CV 5/5; 44/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag\n",
      "[CV 5/5; 44/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=sag;, score=nan total time=   1.1s\n",
      "[CV 1/5; 45/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 1/5; 45/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.0s\n",
      "[CV 2/5; 45/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 2/5; 45/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.3s\n",
      "[CV 3/5; 45/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 3/5; 45/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.1s\n",
      "[CV 4/5; 45/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 4/5; 45/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.1s\n",
      "[CV 5/5; 45/45] START classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga\n",
      "[CV 5/5; 45/45] END classify__C=1.0, classify__penalty=elasticnet, classify__solver=saga;, score=nan total time=   1.1s\n",
      "Best score: 0.7995982110634652\n",
      "Best parameter set: \n",
      "\tclassify__C: 0.1\n",
      "\tclassify__penalty: 'l1'\n",
      "\tclassify__solver: 'liblinear'\n",
      "Test score: 0.7989228007181327\n"
     ]
    }
   ],
   "source": [
    "#perform grid search\n",
    "x_train = train_data.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "y_train = train_data['labels'].values\n",
    "\n",
    "x_test = test_data.drop('labels', axis=1)\n",
    "y_test = test_data['labels'].values\n",
    "\n",
    "grid(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for the execution of the best model that was finally obtained\n",
    "def run(fold, df, clf, x_valid_total, y_valid_total, preds_total_valid):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train = df_train.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "    y_train = df_train['labels'].values\n",
    "    \n",
    "    x_valid = df_valid.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "    y_valid = df_valid['labels'].values\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    preds_train = clf.predict(x_train)\n",
    "    preds_valid = clf.predict(x_valid)\n",
    "\n",
    "    score_train = metrics.fbeta_score(y_train, preds_train, beta=2)\n",
    "    \n",
    "    score_valid = metrics.fbeta_score(y_valid, preds_valid, beta=2)\n",
    "    print(\"Validation Fold: \" + str(fold) + \": \" + str(score_valid))\n",
    "    \n",
    "    if fold == 0:\n",
    "        x_valid_total = x_valid\n",
    "        y_valid_total = y_valid\n",
    "        preds_total_valid = preds_valid\n",
    "        \n",
    "    else:\n",
    "        x_valid_total = np.concatenate((x_valid_total, x_valid), axis=0)\n",
    "        y_valid_total = np.concatenate((y_valid_total, y_valid), axis=None)\n",
    "        preds_total_valid = np.concatenate((preds_total_valid, preds_valid), axis=None)\n",
    "    \n",
    "    return score_valid, x_valid_total, y_valid_total, preds_total_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Fold: 0: 0.7883759733036706\n",
      "Validation Fold: 1: 0.8011744966442953\n",
      "Validation Fold: 2: 0.8173744102137107\n",
      "Validation Fold: 3: 0.7838745800671892\n",
      "Validation Fold: 4: 0.7993338884263114\n",
      "Average fold score: 0.7980266697310354\n"
     ]
    }
   ],
   "source": [
    "#execute the best model that was found using grid search\n",
    "x_valid_total = None\n",
    "y_valid_total = None\n",
    "preds_total = None\n",
    "\n",
    "folds = 5\n",
    "\n",
    "sampling_strategy_o = 0.40\n",
    "\n",
    "if alg == 'logistic regression':\n",
    "    clf = linear_model.LogisticRegression(class_weight='balanced', solver='liblinear', C=0.1, penalty='l1')\n",
    "    \n",
    "if alg == 'decision tree':\n",
    "    clf = tree.DecisionTreeClassifier(random_state=0, criterion='gini', max_depth=10)\n",
    "    \n",
    "if alg == 'support vector machine':\n",
    "    clf = svm.LinearSVC(class_weight='balanced', C=0.1, loss='squared_hinge')\n",
    "    \n",
    "if lang == 'tf-idf':\n",
    "    pipe = imb_pipeline([\n",
    "                ('tfidf', column_transformer),\n",
    "                ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                ('classify', clf)\n",
    "        ])\n",
    "        \n",
    "else:\n",
    "    pipe = imb_pipeline([\n",
    "                ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                ('classify', clf)\n",
    "    ])\n",
    "\n",
    "avg = 0\n",
    "for i in range(0, folds):\n",
    "    run_fold = run(i, train_data, pipe, x_valid_total, y_valid_total, preds_total)\n",
    "    avg = avg + run_fold[0]\n",
    "    x_valid_total = run_fold[1]\n",
    "    y_valid_total = run_fold[2]\n",
    "    preds_total = run_fold[3]\n",
    "    \n",
    "avg = avg/folds\n",
    "print(\"Average fold score: \" + str(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.7992815446789401\n"
     ]
    }
   ],
   "source": [
    "#determine score on test set and averaged out over validation and test set\n",
    "x_train = train_data.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "y_train = train_data['labels'].values\n",
    "\n",
    "x_test = test_data.drop('labels', axis=1)\n",
    "y_test = test_data['labels'].values\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "preds = pipe.predict(x_test)\n",
    "\n",
    "x_valid_total = np.concatenate((x_valid_total, x_test), axis=0)\n",
    "y_valid_total = np.concatenate((y_valid_total, y_test), axis=None)\n",
    "preds_total = np.concatenate((preds_total, preds), axis=None)\n",
    "\n",
    "auc = metrics.fbeta_score(y_test, preds, beta=2)\n",
    "print(\"Test score: \" + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[2890  534]\n",
      " [  90  712]]\n",
      "Normalized confusion matrix\n",
      "[[0.84404206 0.15595794]\n",
      " [0.11221945 0.88778055]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAEWCAYAAADfK6SWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmk0lEQVR4nO3deZgU1fn28e89oAiCCLKI4IKKxi0aNGo0bjGu8b3E/IxrFJfEGLckmhg1JhKNiWZRY9QYNUQ07nFD476FuIOKKKhIFALILuIGwcHn/aPOYDPO0jM9PTU9c3+4+qL71Kmqp7u6nzlVp+qUIgIzM2ueqrwDMDOrZE6iZmYlcBI1MyuBk6iZWQmcRM3MSuAkamZWAidRQFJXSfdIWiTpthKWc7ikh1oytrxI2knSG21lfZLWkxSSOrdWTJWg9uci6X5Jw8uwnomSdm3p5bYHqqTzRCUdBpwKfAH4ABgPnB8RT5a43COAk4EdIqK61DjbOkkBDImIKXnHUh9JU4HvRMQj6fV6wNvASi29jSRdC8yIiLNbcrmtoRyfSyV/HnmomJaopFOBS4BfA/2BdYArgP1bYPHrApM7QgIthlt75ePPth2KiDb/AHoCHwLfaqBOF7Ik+056XAJ0SdN2BWYApwFzgVnA0WnaL4GlwCdpHccCI4C/Fyx7PSCAzun1UcBbZK3ht4HDC8qfLJhvB2AssCj9v0PBtCeA84Cn0nIeAvrU895q4j+9IP5hwL7AZOBd4KyC+tsCzwDvpbqXASunaWPSe/kovd+DC5b/U2A2cH1NWZpng7SOoen1WsA8YNcitt0o4LT0fGBa94m1lltVa33XA58Ci1OMpxdsg+HAf4H5wM+K3P4rbJdUFsCGwHFp2y9N67qnnvcRwPHAm+lzvZzP9uSqgLOBaWn7XAf0rPXdOTbFPSbF8xRwcVrWW2TflaOA6WkZwwvW/Q3gJeD9NH1EA9/NJ8ha8AAvp/dU84iabQbclrb1ohTTZqm8zs8DmAp8vZTfWnt95B5AUUHC3kB1zRelnjrnAs8C/YC+wNPAeQUbtjrVWYks+XwM9ErTR7Bi0qz9evkXFVg1fZk3TtMGFHwBjyL9WIHewELgiDTfoen1GgVf9v8AGwFd0+sL6nlvNfH/IsX/XbIkdiPQA9iMLOEMTvW3BrZP610PeA34YcHyAtiwjuVfmH4gXSlIaqnOd4FJQDfgQeD3RW67Ywp+iIel93xLwbS7C2IoXN9U0o+21ja4OsW3JfA/YJMitv/y7VLXZwBcC/yqkfcRwL3A6mR7QfOAvQvexxRgfaA7cAdwfa24ryP77nRN8VQDRwOdgF+RJdjL0+e/J9kf1u4Fn80WZMn6i8AcYFjt72bB9+o7dcR/HPA6sFpBzD34LCGOL6j7uc+DFZNos39r7fGRewBFBQmHA7MbqfMfYN+C13sBUws27GIKkjDZX8nt0/MRNC2Jvgf8H9C1VgxH8VkSPQJ4vtb0Z4Cj0vMngLMLpp0APFDPe6uJv1N63SPFs11BnRdqflh1zP9D4M6C13Ul0aXAKrXKZtRazmjgFWACqeVRxLbbgOyPRxVwJfA9PmtxjgJOrWt91J9EBxWUPQ8cUsT2X75d6voMKD6JfrXg9a3AGen5o8AJBdM2JmvN1fwRC2D9Wt+TNwteb5Hq9C8oWwBsVU8slwAX1/5uFnyvvlOr/lfJvu8b1bO81dMyetb3ebBiEm32b609PirlmOgCoE8jx5PWItudqjEtlS1fRqx4zPNjslZDk0TER2S7wMcDsyT9U9IXioinJqaBBa9nNyGeBRGxLD1fnP6fUzB9cc38kjaSdK+k2ZLeJzuO3KeBZQPMi4gljdS5Gtgc+FNE/K+RugBExH/IDh1sBexE1pp7R9LGwC7Av4pZToH6PrPGtn9LaMq6O5Mdu68xvdayam87IqK+7bmdpMclzZO0iOy719j2JM27NlnCHx4Rk1NZJ0kXSPpP+n5MTdWLWiat9FurFJWSRJ8h23Ub1kCdd8g6iGqsk8qa4yOy3dYaaxZOjIgHI2IPsl3518mSS2Px1MQ0s5kxNcWfyeIaEhGrAWcBamSeaGiipO5kLaC/AiMk9W5CPP8CDiQ7LjszvR4O9CI7w6LJ8dShoe2/wvaUtML2bMa6ill3NSsmylLWcSPZXsDaEdGTrEXf2PZEUlfgLuCSiLi/YNJhZB2yXyfrb1ivZpYiY23J31rFq4gkGhGLyI4HXi5pmKRuklaStI+k36ZqNwFnS+orqU+q//dmrnI8sLOkdST1BM6smSCpv6T9Ja1Kltg/JOsEqe0+YCNJh0nqLOlgYFOylli59SA7bvthaiV/v9b0OWTH75rij8C4iPgO8E+yHzIAkkZIeqKBef8FnETWgQHZLudJZLvYy+qZp6kxNrT9XwY2k7SVpFXIDteUsq661v0jSYPTH5tfkx33bamzPXoA70bEEknbkiXBYowEXo+I39Yq70H23V1A9sfl17WmN/Z5tORvreJVRBIFiIg/kJ0jejbZQf3pZD/Eu1KVXwHjyI7XvQK8mMqas66HgVvSsl5gxcRXleJ4h6xneRc+n6SIiAXAfmS9lAvIepj3i4j5zYmpiX5M9kP7gKyVfEut6SOAUZLek3RQYwuTtD9Z517N+zwVGCrp8PR6bbLe5vr8i+yHW5NEnyT78Y6pdw74DdkP9T1JP24sRhrY/mk39lzgEbLe9drnFf8V2DSt664i1lXbSLIzCsaQna2xhOy845ZyAnCupA/IEtatRc53CHCApA8LHjuRdXJNI9srmkTWSVSosc+jxX5r7UFFnWxvbZOk8cDu6Q+HWYfiJGpmVoKK2Z03M2uLnETNzErgJGpmVoJ2ORiCOncNrdwj7zCsCTYdMijvEKyJJk54aX5E9C1lGZ1WWzeienHjFYFYPO/BiNi7lPWVQ/tMoiv3oMvGjZ65Y23IP+67MO8QrIk2Wat77Svymiyql9DlC4cUVXfJS38q9oqqVtUuk6iZVQgBavTiqzbNSdTM8qXK7ppxEjWzfLklambWXIKqTnkHURInUTPLj/DuvJlZ88m782ZmJXFL1MysBG6Jmpk1l9wSNTNrNuHeeTOz5nNL1MysNFU+Jmpm1jw+T9TMrETunTczay5f9mlmVhrvzpuZNZN82aeZWWncEjUzK4FbomZmzeWT7c3Mms+XfZqZlcItUTOz0viYqJlZCdwSNTMrQYW3RCv7T4CZVTalY6LFPBpcjNaW9LikSZImSvpBKh8haaak8emxb8E8Z0qaIukNSXsVlO+dyqZIOqOxt+CWqJnlSlUt0parBk6LiBcl9QBekPRwmnZxRPx+hXVKmwKHAJsBawGPSNooTb4c2AOYAYyVNDoiJtW3YidRM8uNALXA7nxEzAJmpecfSHoNGNjALPsDN0fE/4C3JU0Btk3TpkTEW2Sx3Zzq1ptEvTtvZvlREx7FLlJaD/gS8FwqOknSBEkjJfVKZQOB6QWzzUhl9ZXXy0nUzHIkpOIeQB9J4woex31uaVJ34HbghxHxPvBnYANgK7KW6h9a+h14d97MctWE3fn5EbFNA8tZiSyB3hARdwBExJyC6VcD96aXM4G1C2YflMpooLxObomaWa6qqqqKejREWSb+K/BaRFxUUD6goNoBwKvp+WjgEEldJA0GhgDPA2OBIZIGS1qZrPNpdEPrdkvUzPLTxOOdDdgROAJ4RdL4VHYWcKikrYAApgLfA4iIiZJuJeswqgZOjIhlAJJOAh4EOgEjI2JiQyt2EjWz3Ai1VO/8k9Sdju9rYJ7zgfPrKL+voflqcxI1s1y1RBLNk5OomeXKSdTMrAROomZmzSVQlZOomVmztFTHUp6cRM0sV06iZmalqOwc6iRqZjmSW6JmZiVxEjUzayahRq+Lb+ucRM0sX5XdEHUSNbMc+ZiomVlpnETNzErgJGpmVgJf9mklGdh/df484kj69u5BAKPufIq/3PwEm280kIvOOIRVuqxEdfWn/PjCW3hx0jR69ujKZT//NoMH9WHJ0k84+bwbeO0/swDY/Sub8JvTDqRTVRXX3/00l4x6uOGVW4vY96gLWLVrF6o6iU5VVdx46Slcft2D/OvZSahK9O7ZnV+eehD91lht+TwTJ09n+KlX8JszDmWPr34xx+jzVXD/pIpVtiQqaRnwSkHRsIiYWk/dDyOie7liacuqqz/l7EvuYMIbM+jerQuPX/dTnnjudX558jB+e839PPL0JPbYYVN+ecow/t/xf+S0o/filckzOOL0qxmybn9+99ODGHbCn6iqEr87/SAOOOky3pnzHo+N+gn3j3mFN96enfdb7BCuuuA4evVcdfnr4QfuwolH7gXAjXc/xVU3PsLZJ38TgGXLPuWPI+9n+6FDcom1ran0JFrOE7QWR8RWBY+pZVxXxZqz4H0mvDEDgA8//h+Tp85mQN/ViYAeq64CwGrduzJ73iIANh68Jv8eNxmAN6fNYZ0Bvenbuwdbb7Yeb02fz7SZC/ikehl3PPwi++7ScVs4eevebZXlzxcvWbpCorj5nqfYfcfN6b16h2w3fE4T7vbZJrXaWa6Sukt6VNKLkl6RtH8ddQZIGiNpvKRXJe2UyveU9Eya97Z0W9R2Z+0BvfnixoN4YeJUzrroH5x7yjBevfc8zv3BAZx7+d0AvPrmTPbbbUsAhm66Lmuv2Zu1+q3OgL49mTln4fJlvTNnIQP69szlfXQ0Epxw9jUcdsql3H7/c8vLLxv1AHsf+Wvuf+Ilvn/EHgDMnb+Ix56eyLe+sX1e4bY9LXzf+dZWziTaNSXD8ZLuBJYAB0TEUGA34A/6/J+Xw4AHI2IrYEtgvKQ+wNnA19O844BTa69M0nE196OO6sVlfFvlsWrXlbnuwu9w5kW388FHSzjm/3birIvuYPP9fs7PLr6dS39+OACXjHqYnj26MeaGMzju4F2YMHkGyz79NOfoO7a//e773PSnH3DZucdwy73P8MIrbwFw0vC9eeC6s9hn1y9xyz1PA/C7q+7hB8fsU/FX6bSkSm+JlrNjaXFKhsDye0L/WtLOwKfAQKA/UHjQbiwwMtW9KyLGS9oF2BR4Kn2QKwPP1F5ZRFwFXAVQ1a1flOUdlUnnTlWMuvC73PbAOO59/GUADt1vO874wz8AuOuRl/jjzw4D4IOPlnDSuX9fPu/Ld/+SaTMX0LXLygzs32t5+Vr9ezErHQKw8urXJ2vx9169O1/7ymZMnDydrbdYf/n0fXfbipPP+Rvf//aeTHpzBmdccBMA773/EU+OfZ3OVZ3YbYfNcok9bxJUuXe+aIcDfYGtI+ITSVOBVQorRMSYlGS/AVwr6SJgIfBwRBzairG2qj/9/HAmT53NFTc+trxs1rxF7Dh0CE+9+CY7f3kj3po+D8iOjy5espRPqpdx5LAdePqlKXzw0RJenDSNDdbpyzprrcGsue/xzT2G8t2fX5vTO+o4Fi9ZyqefBqt268LiJUt55qXJHHfo15k2cz7rDuwDwBPPTmK9QX0B+Offzlg+7y8uupWdtv1Ch02gmbbdyixGaybRnsDclEB3A9atXUHSusCMiLhaUhdgKNktTS+XtGFETJG0KjAwIia3Yuxls/2W63PIN7Zj4pszGXND9gM77/LR/PD8G/nNaQfSuVMVS5ZW88NfZ62XjQevyRXnHEEQvP7WLE4+7wYg6/E9/be3cvulJ9Kpk7hh9LO8/pZ75sttwcIPOPVX1wOwbNky9tn1S+y4zcac9qvrmTZzHlUSA/r14mcnHZBzpG1XhedQFFGePd/apy2lY5v3AN3JjmtuD+wTEVNr6koaDvwE+AT4EDgyIt6W9DXgQqBLWtzZETG6vnVXdesXXTY+qCzvy8rjpfsuzDsEa6JN1ur+QkRsU8oyVllzo1h3+J+Kqjv5t3uXvL5yKFtLtPZ5nxExH/hKQ3UjYhQwqo7pjwFfLkOYZpYnVX5L1FcsmVluhDuWzMxK4iRqZtZc3p03M2s+UfnXzjuJmlmOKv88UV97Zma5kop7NLwMrS3pcUmTJE2U9INU3lvSw5LeTP/3SuWSdKmkKZImSBpasKzhqf6b6bTLBjmJmll+0mWfxTwaUQ2cFhGbkp2DfqKkTYEzgEcjYgjwaHoNsA8wJD2OA/4MWdIFzgG2A7YFzqlJvPVxEjWz3NQcEy11AJKImBURL6bnHwCvkY3PsT+fnXs+ChiWnu8PXBeZZ4HVJQ0A9iK7zPzdiFgIPAzs3dC6fUzUzHLVhEOifSSNK3h9VRp4qNbytB7wJeA5oH9EzEqTZpMNegRZgp1eMNuMVFZfeb2cRM0sV03oWJrf2GWfaazh24EfRsT7hcuOiJDU4te5e3fezHLVEh1L2XK0ElkCvSEi7kjFc9JuOun/ual8JrB2weyDUll95fVyEjWz/KhljommAd7/CrwWERcVTBoN1PSwDwfuLig/MvXSbw8sSrv9DwJ7SuqVOpT2TGX18u68meVGFNXzXowdgSOAVySNT2VnARcAt0o6FpgG1Azvdh+wLzAF+Bg4GiAi3pV0HtkA8QDnRsS7Da3YSdTMctUS59pHxJPUfyem3euoH8CJ9SxrJDCy2HU7iZpZrir9iiUnUTPLjwcgMTNrPg9AYmZWIidRM7MSeFBmM7Pm8jFRM7PmUzsYT9RJ1MxyVeE51EnUzPJVVeFZ1EnUzHIjuWPJzKwkFZ5DnUTNLF/ttmNJ0p+AegcwjYhTyhKRmXUoFZ5DG2yJjmtgmplZyUR2mlMlqzeJRsSowteSukXEx+UPycw6kko/JtroyPaSviJpEvB6er2lpCvKHpmZtX8q7nbJbbkHv5jbg1xCdhvRBQAR8TKwcxljMrMOQmTniRbzaKuK6p2PiOm1etCWlSccM+to2nB+LEoxSXS6pB2ASHfT+wHwWnnDMrOOotJPcSpmd/54snuRDATeAbainnuTmJk1RbG3S27LebbRlmhEzAcOb4VYzKwD6tSWM2QRiumdX1/SPZLmSZor6W5J67dGcGbW/rXEfefzVMzu/I3ArcAAYC3gNuCmcgZlZh1D1jtf3KOtKiaJdouI6yOiOj3+DqxS7sDMrAMoshXalluiDV073zs9vV/SGcDNZNfSHwzc1wqxmVkH0IbzY1Ea6lh6gSxp1rzF7xVMC+DMcgVlZh1HW25lFqOha+cHt2YgZtbxCOjUlg94FqGoK5YkbQ5sSsGx0Ii4rlxBmVnHUdkptIgkKukcYFeyJHofsA/wJOAkamYlkSr/HkvF9M4fCOwOzI6Io4EtgZ5ljcrMOoxKv2KpmCS6OCI+BaolrQbMBdYub1hm1lG01ClOkkamC4JeLSgbIWmmpPHpsW/BtDMlTZH0hqS9Csr3TmVT0plJDSrmmOg4SasDV5P12H8IPFPEfGZmjWrBVua1wGV8/lDjxRHx+xXXqU2BQ4DNyC4iekTSRmny5cAewAxgrKTRETGpvpUWc+38CenplZIeAFaLiAmNvx8zs4ZJarHe+YgYI2m9IqvvD9wcEf8D3pY0Bdg2TZsSEW+l+G5OdZueRCUNbWhaRLxYZLBmZvVqwnmifSQV3vvtqoi4qoj5TpJ0JNl9406LiIVko9I9W1BnRioDmF6rfLuGFt5QS/QPDUwL4GsNLThPX9pkHZ567rK8w7AmeHX6orxDsJwU0zGTzI+IbZq4+D8D55HlrPPI8toxTVxGgxo62X63llyRmVltorxXLEXEnOXrkq4G7k0vZ7JiB/mgVEYD5XVqwh8BM7OWV85RnCQNKHh5AFDTcz8aOERSF0mDgSHA88BYYIikwZJWJut8Gt3QOoq6YsnMrByklrvsU9JNZBcG9ZE0AzgH2FXSVmS781NJY4BExERJt5J1GFUDJ0bEsrSck4AHgU7AyIiY2NB6nUTNLFctdel8RBxaR/FfG6h/PnB+HeX30YSR6ooZ2V6Svi3pF+n1OpK2bWw+M7NidIQrlq4AvgLUZPkPyE5GNTMrSUe57/x2ETFU0ksAEbEwHXA1MytZpfduF5NEP5HUiezALJL6Ap+WNSoz6zDacCOzKMUk0UuBO4F+ks4nG9Xp7LJGZWYdQkte9pmXYq6dv0HSC2TD4QkYFhGvlT0yM+sQKjyHFjUo8zrAx8A9hWUR8d9yBmZm7V9Nx1IlK2Z3/p98dsO6VYDBwBtkQ0iZmZWkwnNoUbvzWxS+TqM7nVBPdTOz4pVwSWdb0eQrliLiRUkNDg1lZlYsVfit6oo5JnpqwcsqYCjwTtkiMrMOQ0DnCj9RtJiWaI+C59Vkx0hvL084ZtbRlHMovNbQYBJNJ9n3iIgft1I8ZtaBZL3zeUdRmoZuD9I5Iqol7diaAZlZB9LGBxcpRkMt0efJjn+OlzQauA34qGZiRNxR5tjMrAPoCOeJrgIsILunUs35ogE4iZpZSQR0ascdS/1Sz/yrfJY8a0RZozKzDkJUteNTnDoB3aHOd+gkamYly25Ul3cUpWkoic6KiHNbLRIz63ja+RVLFf7WzKwStOeOpd1bLQoz65Da9e58RLzbmoGYWcfU7gdlNjMrF9Ex7rFkZlYeaufXzpuZlVtlp1AnUTPLUUe5PYiZWdlUdgp1EjWzXIkq986bmTWPe+fNzEpU6b3zlf5HwMwqnIp8NLocaaSkuZJeLSjrLelhSW+m/3ulckm6VNIUSRPSXYxr5hme6r8paXhj63USNbP8pPNEi3kU4Vpg71plZwCPRsQQ4NH0GmAfYEh6HAf8GbKkC5wDbAdsC5xTk3jr4yRqZrkR0Ekq6tGYiBgD1L5cfX9gVHo+ChhWUH5dZJ4FVpc0ANgLeDgi3o2IhcDDfD4xr8DHRM0sV004ItpH0riC11dFxFWNzNM/Imal57OB/un5QGB6Qb0Zqay+8no5iZpZrprQrzQ/IrZp7noiIiS1+IDy3p03s9xkpzipqEczzUm76aT/56bymcDaBfUGpbL6yuvlJGpmuZKKezTTaKCmh304cHdB+ZGpl357YFHa7X8Q2FNSr9ShtGcqq5d3580sR0ItdOGnpJuAXcmOnc4g62W/ALhV0rHANOCgVP0+YF9gCvAxcDRk4yhLOg8Ym+qd29jYyk6iZpabmt75lhARh9Yz6XN36YiIAE6sZzkjgZHFrtdJ1MzyU9quepvgJGpmuXISNTMrQUsdE82Lk6iZ5SYblDnvKErjJGpmufLI9mZmJfDuvJXNlTc9zqi7noYIjhy2I98/bDcWLvqIY84ayX9nvcs6A3rzt98cy+qrdcs71A7rvzPncc4fbl7++p05Czn2kN3pu8ZqjLzlMabNmMdVFx7PFzYcBMDY8VO48u8PUl29jM6dO3HC8L3ZeosN8go/d96dL5KkNciGoQJYE1gGzEuvt42Ipa0RRyWZNOUdRt31NI+O+gkrd+7EgadcwV47bc61dz7Fzl/emB8dtScXX/sQF496iF+ePCzvcDusdQb25W8XnQzAsmWf8s3vXsjO223KkqWfcP7ph/G7K+9eoX7P1bpx4VlH0Kf3arw1bQ6nnfc37rzmjLoW3UG03Mn2eWmVyz4jYkFEbBURWwFXAhfXvI6IpZLcIq5l8tTZbLP5enRbZWU6d+7EjkM35J7Hx3P/vyZw6H7bAXDofttx3xMTco7Uarzwyn9Yq39v1uzXi/UG9WOdgX0/V2ej9deiT+/VABi8Tj/+t7SapZ9Ut3aobUeRl3y25cOmuV07L+laSVdKeg74raQRkn5cMP1VSeul59+W9Lyk8ZL+IqlTXnG3lk02WItnxk/h3fc+5OMlS3n46YnMnLOQue9+wJp9egLQf43VmPvuBzlHajUefXICX9/pi0XXf+KZiWy0/lqsvFLHbkO01Mj2ecl7AJJBwA4RcWp9FSRtAhwM7JhassuAw+uod5ykcZLGzZs/r/bkirPx4DX5wZF78M2TL+fAUy5n840G0alqxc2VjfidU4C2gk8+qeapsa+z2w5bFFX/7f/O4crrH+Qnx+9f5sjatpYclDkvef8JvC0iljVSZ3dga2BsukVAVz4bzmq5NDjrVQBbb71Ni48ZmIcj9t+BI/bfAYBzLx/NWv1Wp1/vHsyev4g1+/Rk9vxF9O3VI+coDeDZlyaz0fpr0Xv17o3WnTt/EWddeAM/O+VABq65RitE18a13fxYlLxboh8VPK9mxXhWSf8LGFVwDHXjiBjRWgHmaV7aVZ8++13uffxlvrX3Nuy98xbcdO9zANx073Pss0vxu49WPo/8ewK7f7XxbfHBR4s5/fzrOP6IvfjiJuu2QmRtn4r811bl3RItNBXYDyDdeW9wKn8UuFvSxRExN91IqkdETMsnzNZz5E+vYeGij+jcuRO/O/0gevboxo+G78HRZ47k76OfYe01e/O33xyTd5gd3uIlSxn38hR+cvyw5WVjnp3IJdfcy3vvf8Tp51/HhoMHcNEvjuaO+55l5uwFXHvrY1x762MAXPSLo+lVRAu2vWrDe+pFUTYiVCuuUBoBfAhsDtwbEf9I5V3JBkwdCDwHfAXYJyKmSjoYOJOspfoJcGK6uVSdtt56m3jquXH1TbY26NXpi/IOwZroy+uv/kIpt+sA2GSLL8V1dz9RVN1tNyh9feXQ6i3R+nbFI2Ix2SjSdU27BbiljGGZWV4qvCXalnbnzayDkXztvJlZSSo7hTqJmlneKjyLOomaWY7a9ulLxXASNbNcVfghUSdRM8uPcBI1MyuJd+fNzErglqiZWQkqPIc6iZpZjtr6YKFFcBI1s1z5mKiZWTP5RnVmZqVyEjUza75K353Pe2R7M+vgWupun5KmSnol3dByXCrrLelhSW+m/3ulckm6VNIUSRPSQPDN4iRqZrlq4bt97pZuI1QzePMZwKMRMYTsLhlnpPJ9gCHpcRzw5+bG7yRqZvkq7z2T9wdGpeejgGEF5ddF5llgdUkDmrMCJ1Ezy03NoMzFPIA+NbdFT4/jai0ugIckvVAwrX9EzErPZwP90/OBwPSCeWeksiZzx5KZ5aoJjcz5jdxj6asRMVNSP+BhSa8XToyIkNTiN5VzS9TM8tVCu/MRMTP9Pxe4E9gWmFOzm57+n5uqzwTWLph9UCprMidRM8tRsXedbziLSlpVUo+a52Q3vXwVGA0MT9WGk91RmFR+ZOql3x5YVLDb3yTenTezXLXQKE79gTuVLawzcGNEPCBpLHCrpGOBacBBqf59wL7AFOBj4OjmrthJ1Mxy01KDMkfEW8CWdZQvAHavozyAE0tfs5OomeWs0q9YchI1s1x5UGYzsxJUeA51EjWzHBV5XXxb5iRqZjmr7CzqJGpmufGgzGZmJfLuvJlZCXyKk5lZKSo7hzqJmlm+KjyHOomaWX6KvfVHW+Ykama5UoVnUSdRM8tVZadQJ1Ezy1mFN0SdRM0sT40PuNzWOYmaWW5aajzRPDmJmlmunETNzErg3Xkzs+byeaJmZs1X5N2Q2zQnUTPLV4VnUSdRM8uVj4mamZXAgzKbmZXCSdTMrPm8O29m1kzt4YolRUTeMbQ4SfOAaXnHUSZ9gPl5B2FN0l632boR0beUBUh6gOzzKcb8iNi7lPWVQ7tMou2ZpHERsU3ecVjxvM3at6q8AzAzq2ROomZmJXASrTxX5R2ANZm3WTvmY6JmZiVwS9TMrAROomZmJfDJ9jmTtAx4paBoWERMrafuhxHRvVUCswZJWgN4NL1cE1gGzEuvt42IpbkEZq3Ox0Rz1pTE6CTaNkkaAXwYEb8vKOscEdX5RWWtxbvzbYyk7pIelfSipFck7V9HnQGSxkgaL+lVSTul8j0lPZPmvU2SE24rknStpCslPQf8VtIIST8umP6qpPXS829Lej5tw79I6pRX3FYaJ9H8dU0/pPGS7gSWAAdExFBgN+AP0ueuLj4MeDAitgK2BMZL6gOcDXw9zTsOOLXV3oXVGATsEBH1fvaSNgEOBnZM23AZcHjrhGctzcdE87c4/ZAAkLQS8GtJOwOfAgOB/sDsgnnGAiNT3bsiYrykXYBNgadSzl0ZeKZ13oIVuC0iljVSZ3dga2Bs2lZdgbnlDszKw0m07Tkc6AtsHRGfSJoKrFJYISLGpCT7DeBaSRcBC4GHI+LQ1g7YVvBRwfNqVtzbq9mOAkZFxJmtFpWVjXfn256ewNyUQHcD1q1dQdK6wJyIuBq4BhgKPAvsKGnDVGdVSRu1Ytz2eVPJtg2ShgKDU/mjwIGS+qVpvdM2tQrklmjbcwNwj6RXyI5rvl5HnV2Bn0j6BPgQODIi5kk6CrhJUpdU72xgcvlDtnrcDhwpaSLwHGlbRMQkSWcDD0mqAj4BTqT9Dt/YrvkUJzOzEnh33sysBE6iZmYlcBI1MyuBk6iZWQmcRM3MSuAk2kFJWlZw7f1tkrqVsKxrJR2Ynl8jadMG6u4qaYdmrGNqurS1qPJadT5s4rpWuObdrCFOoh3X4ojYKiI2B5YCxxdOlNSsc4gj4jsRMamBKrsCTU6iZm2Vk6gB/BvYMLUS/y1pNDBJUidJv5M0VtIESd8DUOYySW9IegToV7MgSU9I2iY93zuNKPVyGplqPbJk/aPUCt5JUl9Jt6d1jJW0Y5p3DUkPSZoo6RqySyUbJOkuSS+keY6rNe3iVP6opL6pbANJD6R5/i3pCy3yaVqH4iuWOrjU4twHeCAVDQU2j4i3UyJaFBFfTldBPSXpIeBLwMZkA570ByYBI2stty9wNbBzWlbviHhX0pUUjL0p6Ubg4oh4UtI6wIPAJsA5wJMRca6kbwDHFvF2jknr6Eo2uMftEbEAWBUYFxE/kvSLtOyTyG4gd3xEvClpO+AK4GvN+BitA3MS7bi6Shqfnv8b+CvZbvbzEfF2Kt8T+GLN8U6y6/qHADsDN6XRit6R9Fgdy98eGFOzrIh4t544vg5sWjDa32rKxkHdGfhmmvefkhYW8Z5OkXRAer52inUB2WhYt6TyvwN3pHXsANxWsO4umDWRk2jHtcIQfAApmRSOQiTg5Ih4sFa9fVswjipg+4hYUkcsRZO0K1lC/kpEfCzpCWqNflUg0nrfq/0ZmDWVj4laQx4Evp/GLUXSRpJWBcYAB6djpgPIBo+u7VlgZ0mD07y9U/kHQI+Ceg8BJ9e8kLRVejqGbPBpJO0D9Gok1p7AwpRAv0DWEq5RBdS0pg8jO0zwPvC2pG+ldUjSlo2sw+xznEStIdeQHe98UdKrwF/I9l7uBN5M066jjsGfI2IecBzZrvPLfLY7fQ9wQE3HEnAKsE3quJrEZ2cJ/JIsCU8k263/byOxPgB0lvQacAFZEq/xEbBteg9fA85N5YcDx6b4JgKfuxWLWWM8ipOZWQncEjUzK4GTqJlZCZxEzcxK4CRqZlYCJ1EzsxI4iZqZlcBJ1MysBP8fIjIvAWfrf4gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix obtained by the best model\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "        pipe,\n",
    "        pd. DataFrame(x_test),\n",
    "        y_test,\n",
    "        display_labels=le.classes_,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
