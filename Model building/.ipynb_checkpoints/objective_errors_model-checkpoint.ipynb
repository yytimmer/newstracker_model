{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection, metrics, linear_model, tree\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import scipy.sparse\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\n",
    "\n",
    "#word2vec\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('C:\\\\Users\\\\yytimmer\\\\OneDrive - ugentbe\\\\Bureaublad\\\\Doctoraat\\\\Papers\\\\News updates\\\\Predictive model\\\\Models\\\\roularta-320.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '..\\\\Data\\\\'\n",
    "\n",
    "#read data\n",
    "my_data = pd.read_csv(filepath + 'input_data_model_obj.csv', quotechar='\"', delimiter=',')\n",
    "my_train_data = pd.read_csv(filepath + 'input_data_model_obj_train.csv', quotechar='\"', delimiter=',')\n",
    "my_test_data = pd.read_csv(filepath + 'input_data_model_obj_test.csv', quotechar='\"', delimiter=',')\n",
    "\n",
    "my_train_data['test'] = False\n",
    "my_test_data['test'] = True\n",
    "my_data = my_train_data.append(my_test_data, ignore_index = True)\n",
    "\n",
    "#fill up NULL values in the original data with 0\n",
    "my_data['fraction_total_changed_intro_original'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_intro_new'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_text_original'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_text_new'].fillna(0, inplace=True) \n",
    "my_data['original_changed_text'].fillna('', inplace=True) \n",
    "my_data['new_changed_text'].fillna('', inplace=True) \n",
    "my_data['topic'].fillna('other', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the appropriate learning algorithm and language model\n",
    "\n",
    "#LEARNING ALGORITHM\n",
    "#alg = 'logistic regression'\n",
    "#alg = 'decision tree'\n",
    "alg = 'support vector machine'\n",
    "\n",
    "#LANGUAGE MODEL\n",
    "\n",
    "#lang = 'no text'\n",
    "lang = 'tf-idf'\n",
    "#lang = 'word2vec'\n",
    "#lang = 'bertje_full'\n",
    "#lang = 'bertje_minimized'\n",
    "#lang = 'bertje_lemmatized'\n",
    "#lang = 'sbert_full'\n",
    "#lang = 'sbert_minimized'\n",
    "#lang = 'sbert_lemmatized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    20583\n",
      "True       546\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#show distribution of positive and negative samples\n",
    "print(my_data['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the features to be inputted to the model\n",
    "\n",
    "my_data['original_time'] = pd.to_datetime(my_data['original_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "my_data['new_time'] = pd.to_datetime(my_data['new_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "my_data['first_time'] = pd.to_datetime(my_data['first_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "my_data['weekday_original'] = my_data['original_time'].dt.weekday\n",
    "my_data['hour_original'] = my_data['original_time'].dt.hour\n",
    "my_data['weekday_new'] = my_data['new_time'].dt.weekday\n",
    "my_data['hour_new'] = my_data['new_time'].dt.hour\n",
    "my_data['weekday_first'] = my_data['first_time'].dt.weekday\n",
    "my_data['hour_first'] = my_data['first_time'].dt.hour\n",
    "\n",
    "data_to_encode = my_data[['newspaper', 'topic', 'textpart', 'first_wordtype', 'last_wordtype']]\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe_data = pd.DataFrame(ohe.fit_transform(data_to_encode))\n",
    "\n",
    "normalized_continuous_array = ['weekday_original', 'weekday_new', 'hour_original', 'hour_new',\n",
    "    'length_original', 'length_new', 'max_version_number', \n",
    "                               'version_number_progress',\n",
    "                                 'dates_difference', \n",
    "                               'time_difference', 'original_title_length', 'original_intro_length',\n",
    "               'original_text_length', 'new_title_length', 'new_intro_length', 'new_text_length', \n",
    "                               'fraction_original_title_changed', 'fraction_new_title_changed',\n",
    "              'fraction_original_intro_changed', 'fraction_new_intro_changed',\n",
    "              'fraction_original_text_changed', 'fraction_new_text_changed', \n",
    "                                 'original_changed_fraction_text_part', 'new_changed_fraction_text_part', \n",
    "                'levenshtein_maximalized',\n",
    "                               'nr_insert_max', 'nr_delete_max', 'nr_replace_max',\n",
    "              'levenshtein_minimalized',\n",
    "                               'nr_insert_min', 'nr_delete_min', 'nr_replace_min',\n",
    "                               'jaccard', 'capitalized_equality',\n",
    "    'seqratio', 'text_overlap_original', 'text_overlap_new',\n",
    "              'stop_words_ratio',\n",
    "                               'fraction_total_changed_original', 'fraction_total_changed_new',\n",
    "                            'fraction_total_changed_title_original', 'fraction_total_changed_title_new',\n",
    "              'fraction_total_changed_intro_original', 'fraction_total_changed_intro_new',\n",
    "              'fraction_total_changed_text_original', 'fraction_total_changed_text_new',\n",
    "            'ent_original', 'original_token_length', 'adv_orig', 'noun_orig', 'point_orig', 'comma_orig',\n",
    "              'accent_orig', 'haakje_orig', 'doublepoint_orig', 'hyphen_orig', 'threepoints_orig', 'punct_orig', 'x_orig', 'propn_orig',\n",
    "              'pron_orig', 'det_orig', 'sconj_orig', 'space_orig', 'sym_orig', 'num_orig', 'adp_orig',\n",
    "              'intj_orig', 'aux_orig', 'inf_orig', 'pv_verl_ev_orig', 'pv_verl_mv_orig', 'pv_tgw_ev_orig', 'pv_tgw_mv_orig',\n",
    "                'od_prenom_orig', 'od_nom_orig', 'od_postnom_orig', 'od_vrij_orig', 'vd_vrij_orig', 'vd_prenom_orig', \n",
    "              'vd_postnom_orig', 'vd_nom_orig', 'verb_orig', 'cconj_orig', 'adj_sup_orig', 'adj_comp_orig', 'adj_basis_orig',\n",
    "              'ent_new', 'new_token_length', 'adv_new', 'noun_new', 'point_new', 'comma_new',\n",
    "              'accent_new', 'haakje_new', 'doublepoint_new', 'hyphen_new', 'threepoints_new', 'punct_new', 'x_new', 'propn_new',\n",
    "              'pron_new', 'det_new', 'sconj_new', 'space_new', 'sym_new', 'num_new', 'adp_new',\n",
    "              'intj_new', 'aux_new', 'inf_new', 'pv_verl_ev_new', 'pv_verl_mv_new', 'pv_tgw_ev_new', 'pv_tgw_mv_new',\n",
    "                'od_prenom_new', 'od_nom_new', 'od_postnom_new', 'od_vrij_new', 'vd_vrij_new', 'vd_prenom_new', \n",
    "              'vd_postnom_new', 'vd_nom_new', 'verb_new', 'cconj_new', 'adj_sup_new', 'adj_comp_new', 'adj_basis_new',  \n",
    "              'orginal_spelling_ok', 'new_spelling_ok', 'number_comparison', 'changed_position',\n",
    "                               'nr_red_parts', 'nr_green_parts', 'orig_part_of_new', 'new_part_of_orig',\n",
    "                               'one_edit_change', 'sentence_sim', 'diff_sim', \n",
    "                               'doubt_words_orig', 'doubt_words_new',\n",
    "                               'doubt_words_total',\n",
    "                               'negation_original',\n",
    "                               'negation_new', 'temporary',\n",
    "              'colors', 'days', 'currencies', 'months', 'winds', 'states', 'countries', 'cities', 'belgian', 'nationality',\n",
    "              'date_diff', 'person_diff', 'nr_full_sentences_original', 'nr_full_sentences_new',\n",
    "                               'entity_present_in_original', 'entity_present_in_new'                          \n",
    "                        ]\n",
    "\n",
    "if lang == 'bertje_full':\n",
    "    header_bertje_original = ['original_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_new = ['new_bertje_' + str(i) for i in range(0, 768)]\n",
    "    \n",
    "if lang == 'bertje_minimized':\n",
    "    header_bertje_minimized_original = ['original_minimized_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_minimized_new = ['new_minimized_bertje_' + str(i) for i in range(0, 768)]\n",
    "\n",
    "if lang == 'bertje_lemmatized':\n",
    "    header_bertje_lemmatized_original = ['original_lemmatized_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_lemmatized_new = ['new_lemmatized_bertje_' + str(i) for i in range(0, 768)]\n",
    "\n",
    "if lang == 'sbert_full':\n",
    "    header_sbert_original = ['original_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_new = ['new_sbert_' + str(i) for i in range(0, 512)]\n",
    "\n",
    "if lang == 'sbert_minimized':\n",
    "    header_sbert_minimized_original = ['original_minimized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_minimized_new = ['new_minimized_sbert_' + str(i) for i in range(0, 512)]\n",
    "\n",
    "if lang == 'sbert_lemmatized':\n",
    "    header_sbert_lemmatized_original = ['original_lemmatized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_lemmatized_new = ['new_lemmatized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    \n",
    "boolean_features = ['double_word', 'equal_after_subst', 'globally_equal_after_subst']\n",
    "text_array_lemmatized = ['original_lemmatized_minimized_changed_text', 'new_lemmatized_minimized_changed_text']\n",
    "text_array_minimized = ['original_minimized_changed_text', 'new_minimized_changed_text']\n",
    "text_array_changed = ['original_changed_text', 'new_changed_text']\n",
    "\n",
    "text_df = my_data[text_array_lemmatized].fillna('')\n",
    "text_minimized_df = my_data[text_array_minimized].fillna('')\n",
    "my_data = my_data.replace(np.inf, 0)\n",
    "\n",
    "#normalize all continuous variables before continuing\n",
    "normalized_continuous = (my_data[normalized_continuous_array] - my_data[normalized_continuous_array].min())/(my_data[normalized_continuous_array].max() - my_data[normalized_continuous_array].min() + 0.01)\n",
    "\n",
    "if lang == 'bertje_full':\n",
    "    normalized_bertje_original = (my_data[header_bertje_original] - my_data[header_bertje_original].min())/(my_data[header_bertje_original].max() - my_data[header_bertje_original].min() + 0.01)\n",
    "    normalized_bertje_new = (my_data[header_bertje_new] - my_data[header_bertje_new].min())/(my_data[header_bertje_new].max() - my_data[header_bertje_new].min() + 0.01)\n",
    "\n",
    "if lang == 'bertje_minimized':\n",
    "    normalized_bertje_minimized_original = (my_data[header_bertje_minimized_original] - my_data[header_bertje_minimized_original].min())/(my_data[header_bertje_minimized_original].max() - my_data[header_bertje_minimized_original].min() + 0.01)\n",
    "    normalized_bertje_minimized_new = (my_data[header_bertje_minimized_new] - my_data[header_bertje_minimized_new].min())/(my_data[header_bertje_minimized_new].max() - my_data[header_bertje_minimized_new].min() + 0.01)\n",
    "    \n",
    "if lang == 'bertje_lemmatized':\n",
    "    normalized_bertje_lemmatized_original = (my_data[header_bertje_lemmatized_original] - my_data[header_bertje_lemmatized_original].min())/(my_data[header_bertje_lemmatized_original].max() - my_data[header_bertje_lemmatized_original].min() + 0.01)\n",
    "    normalized_bertje_lemmatized_new = (my_data[header_bertje_lemmatized_new] - my_data[header_bertje_lemmatized_new].min())/(my_data[header_bertje_lemmatized_new].max() - my_data[header_bertje_lemmatized_new].min() + 0.01)\n",
    "\n",
    "if lang == 'sbert_full':\n",
    "    normalized_sbert_original = (my_data[header_sbert_original] - my_data[header_sbert_original].min())/(my_data[header_sbert_original].max() - my_data[header_sbert_original].min() + 0.01)\n",
    "    normalized_sbert_new = (my_data[header_sbert_new] - my_data[header_sbert_new].min())/(my_data[header_sbert_new].max() - my_data[header_sbert_new].min() + 0.01)\n",
    "\n",
    "if lang == 'sbert_minimized':\n",
    "    normalized_sbert_minimized_original = (my_data[header_sbert_minimized_original] - my_data[header_sbert_minimized_original].min())/(my_data[header_sbert_minimized_original].max() - my_data[header_sbert_minimized_original].min() + 0.01)\n",
    "    normalized_sbert_minimized_new = (my_data[header_sbert_minimized_new] - my_data[header_sbert_minimized_new].min())/(my_data[header_sbert_minimized_new].max() - my_data[header_sbert_minimized_new].min() + 0.01)    \n",
    "    \n",
    "if lang == 'sbert_lemmatized':\n",
    "    normalized_sbert_lemmatized_original = (my_data[header_sbert_lemmatized_original] - my_data[header_sbert_lemmatized_original].min())/(my_data[header_sbert_lemmatized_original].max() - my_data[header_sbert_lemmatized_original].min() + 0.01)\n",
    "    normalized_sbert_lemmatized_new = (my_data[header_sbert_lemmatized_new] - my_data[header_sbert_lemmatized_new].min())/(my_data[header_sbert_lemmatized_new].max() - my_data[header_sbert_lemmatized_new].min() + 0.01)\n",
    "    \n",
    "boolean = my_data[boolean_features]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = pd.DataFrame({'labels': le.fit_transform(my_data['type'])})\n",
    "\n",
    "test = pd.DataFrame({'test': my_data['test']})\n",
    "\n",
    "all_data = pd.concat([ohe_data, normalized_continuous, boolean, text_minimized_df, labels, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding vector embeddings in case of word2vec\n",
    "\n",
    "if lang == 'word2vec':\n",
    "    word2vec_tokenizer = TfidfVectorizer().build_tokenizer()\n",
    "    \n",
    "    all_data[\"original_tokenized\"] = all_data.apply(lambda x: [word.lower() for word in word2vec_tokenizer(x['original_minimized_changed_text'])], axis=1)\n",
    "    all_data[\"new_tokenized\"] = all_data.apply(lambda x: [word.lower() for word in word2vec_tokenizer(x['new_minimized_changed_text'])], axis=1)\n",
    "\n",
    "    all_data[\"original_word2vec_array\"] = all_data.apply(lambda x: [word2vec_model[word] for word in x[\"original_tokenized\"] if word in word2vec_model], axis=1)\n",
    "    all_data[\"new_word2vec_array\"] = all_data.apply(lambda x: [word2vec_model[word] for word in x[\"new_tokenized\"] if word in word2vec_model], axis=1)\n",
    "\n",
    "    all_data[\"original_word2vec\"] = all_data.apply(lambda x: [float(sum(l))/len(l) for l in zip(*x[\"original_word2vec_array\"])], axis=1)\n",
    "    all_data[\"new_word2vec\"] = all_data.apply(lambda x: [float(sum(l))/len(l) for l in zip(*x[\"new_word2vec_array\"])], axis=1)\n",
    "\n",
    "    original_column_names = ['original_word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "    new_column_names = ['new_word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "    word2vec_column_names = ['word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "\n",
    "    word2vec_data_original = pd.DataFrame(all_data[\"original_word2vec\"].to_list(), columns=original_column_names)\n",
    "    word2vec_data_new = pd.DataFrame(all_data[\"new_word2vec\"].to_list(), columns=new_column_names)\n",
    "    word2vec_data = pd.DataFrame(word2vec_data_original - word2vec_data_new, columns=word2vec_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSE THE APPROPRIATE MODEL\n",
    "\n",
    "if lang == 'no text':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'tf-idf':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, text_df, boolean, labels, test], axis=1)\n",
    "    \n",
    "if lang == 'word2vec':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, word2vec_data_original, word2vec_data_new, boolean, labels, test], axis=1)\n",
    "    all_data[original_column_names] = all_data[original_column_names].fillna(0)\n",
    "    all_data[new_column_names] = all_data[new_column_names].fillna(0)\n",
    "    \n",
    "if lang == 'bertje_full':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_original, normalized_bertje_new, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'bertje_minimized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_minimized_original, normalized_bertje_minimized_new, boolean, labels, test], axis=1)    \n",
    "\n",
    "if lang == 'bertje_lemmatized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_lemmatized_original, normalized_bertje_lemmatized_new, boolean, labels, test], axis=1)\n",
    "    \n",
    "if lang == 'sbert_full':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_original, normalized_sbert_new, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'sbert_minimized':    \n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_minimized_original, normalized_sbert_minimized_new, boolean, labels, test], axis=1)    \n",
    "\n",
    "if lang == 'sbert_lemmatized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_lemmatized_original, normalized_sbert_lemmatized_new, boolean, labels, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up the training data (80%) and the test data (20%)\n",
    "train_data = all_data[all_data[\"test\"]==False].iloc[:, :-1]\n",
    "test_data = all_data[all_data[\"test\"]==True].iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9507310904654973\n"
     ]
    }
   ],
   "source": [
    "#ONLY TO BE EXECUTED IN CASE OF TF-IDF\n",
    "\n",
    "#verify number of features needed for 95% threshold using LSA\n",
    "\n",
    "#transform textual data present in the atomic changes (in the attributes 'original_changed_text' and 'new_changed_text')\n",
    "#into TF-IDF features such that we have all initial features that would be used in the model\n",
    "\n",
    "if lang == 'tf-idf':\n",
    "    vectorizer_original = TfidfVectorizer()\n",
    "    vectorizer_new = TfidfVectorizer()\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        [('tfidf_original', vectorizer_original, 'original_lemmatized_minimized_changed_text'), \n",
    "        ('tfidf_new', vectorizer_new, 'new_lemmatized_minimized_changed_text')],\n",
    "        remainder='passthrough')\n",
    "\n",
    "    temp_train_data = column_transformer.fit_transform(train_data)\n",
    "\n",
    "    truncatedsvd = TruncatedSVD(n_components=1850)\n",
    "    truncatedsvd.fit(temp_train_data)\n",
    "\n",
    "    print(truncatedsvd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define f2 scorer\n",
    "def fbeta_score(y_true, y_pred):\n",
    "    return metrics.fbeta_score(y_true, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the training data into five different folds in order to apply stratified k-fold cross validation\n",
    "#for the final execution of the best model\n",
    "train_data[\"kfold\"] = -1\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_, v_) in enumerate(kf.split(X = train_data, y=train_data['labels'].values)):\n",
    "    train_data.loc[v_, 'kfold'] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that implements grid search for hyperparameter optimization by selecting the optimization algorithm\n",
    "#and parameters accordingly\n",
    "def grid(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    #Grid Search Model\n",
    "    if alg == 'decision tree':\n",
    "        clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "        \n",
    "        param_grid = {\"classify__criterion\": ['entropy', 'gini', 'log_loss'],\n",
    "        \"classify__max_depth\": [2,4,6,8,10,12, 14, 16, 18, 20, 22, 24, 26, 28, 30]}\n",
    "    \n",
    "    if alg == 'logistic regression':\n",
    "        clf = linear_model.LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "        \n",
    "        param_grid = {\"classify__C\":[0.01, 0.1, 1.0], \"classify__penalty\":[\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"classify__solver\": ['newton-cg', \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}\n",
    "    \n",
    "    if alg == 'support vector machine':\n",
    "        clf = LinearSVC(class_weight=\"balanced\", random_state=0)\n",
    "        \n",
    "        param_grid = {\"classify__loss\": ['hinge', 'squared_hinge'],\n",
    "        \"classify__C\":[ 0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \"classify__penalty\":[\"l1\", \"l2\"]}\n",
    "    \n",
    "    sampling_strategy_o = 0.32\n",
    "    \n",
    "    if lang == 'tf-idf':\n",
    "        pipe = imb_pipeline([\n",
    "                    ('tfidf', column_transformer),\n",
    "                    ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                    ('classify', clf)\n",
    "            ])\n",
    "        \n",
    "    else:\n",
    "        pipe = imb_pipeline([\n",
    "                    ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                    ('classify', clf)\n",
    "        ])\n",
    "\n",
    "    \n",
    "    scorer = metrics.make_scorer(fbeta_score, greater_is_better=True, needs_threshold=False)\n",
    "\n",
    "    grid_model = model_selection.GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    refit=True,\n",
    "    verbose=10,\n",
    "    cv=5)\n",
    "    \n",
    "    grid_model.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best score: \" + str(grid_model.best_score_))\n",
    "    print(\"Best parameter set: \")\n",
    "    best_parameters = grid_model.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    best_model = grid_model.best_estimator_\n",
    "    best_model.fit(x_train, y_train)\n",
    "    preds = best_model.predict(x_test)\n",
    "    \n",
    "    score = metrics.fbeta_score(y_test, preds, beta=2)\n",
    "    print(\"Test score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 1/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 2/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 2/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 5/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 1/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.213 total time=   0.9s\n",
      "[CV 2/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.218 total time=   0.9s\n",
      "[CV 3/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.215 total time=   0.9s\n",
      "[CV 4/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.212 total time=   1.0s\n",
      "[CV 5/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.197 total time=   0.9s\n",
      "[CV 1/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 2/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 3/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 4/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 1/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.214 total time=   0.9s\n",
      "[CV 2/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.220 total time=   0.9s\n",
      "[CV 3/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.222 total time=   0.9s\n",
      "[CV 4/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.215 total time=   0.9s\n",
      "[CV 5/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.202 total time=   0.9s\n",
      "[CV 1/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 1/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 2/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 5/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.211 total time=   0.9s\n",
      "[CV 2/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.206 total time=   0.7s\n",
      "[CV 3/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.204 total time=   0.8s\n",
      "[CV 4/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.197 total time=   0.8s\n",
      "[CV 5/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.186 total time=   0.8s\n",
      "[CV 1/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 4/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 5/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.256 total time=   0.9s\n",
      "[CV 2/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.274 total time=   0.9s\n",
      "[CV 3/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.279 total time=   1.0s\n",
      "[CV 4/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.265 total time=   0.9s\n",
      "[CV 5/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.245 total time=   0.8s\n",
      "[CV 1/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 2/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 3/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 4/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 5/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.288 total time=   0.9s\n",
      "[CV 2/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.331 total time=   0.9s\n",
      "[CV 3/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.314 total time=   0.9s\n",
      "[CV 4/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.311 total time=   0.9s\n",
      "[CV 5/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.274 total time=   0.9s\n",
      "[CV 1/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 2/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 4/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 1/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.323 total time=   0.9s\n",
      "[CV 2/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.348 total time=   0.8s\n",
      "[CV 3/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.352 total time=   0.8s\n",
      "[CV 4/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.362 total time=   0.8s\n",
      "[CV 5/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.336 total time=   0.9s\n",
      "[CV 1/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 1/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 2/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 2/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 3/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 4/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 5/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 1/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.347 total time=   0.7s\n",
      "[CV 2/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.379 total time=   0.8s\n",
      "[CV 3/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.388 total time=   1.0s\n",
      "[CV 4/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.391 total time=   0.8s\n",
      "[CV 5/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.347 total time=   0.7s\n",
      "[CV 1/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 2/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 3/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 4/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 5/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 1/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.432 total time=   0.8s\n",
      "[CV 2/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.438 total time=   0.8s\n",
      "[CV 3/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.478 total time=   0.8s\n",
      "[CV 4/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.445 total time=   0.8s\n",
      "[CV 5/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.442 total time=   0.8s\n",
      "[CV 1/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 1/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 2/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 3/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 4/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 5/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 1/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.482 total time=   2.0s\n",
      "[CV 2/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.492 total time=   1.9s\n",
      "[CV 3/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.481 total time=   2.1s\n",
      "[CV 4/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.469 total time=   2.1s\n",
      "[CV 5/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.523 total time=   2.0s\n",
      "[CV 1/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 2/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 3/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 4/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 5/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 1/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.507 total time=   1.2s\n",
      "[CV 2/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.511 total time=   1.2s\n",
      "[CV 3/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.466 total time=   1.1s\n",
      "[CV 4/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.483 total time=   1.2s\n",
      "[CV 5/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.515 total time=   1.2s\n",
      "[CV 1/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 1/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 2/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 2/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 3/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 3/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 4/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 4/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 5/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 1/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.424 total time=   2.6s\n",
      "[CV 2/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 2/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.424 total time=   2.5s\n",
      "[CV 3/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 3/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.417 total time=   2.4s\n",
      "[CV 4/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 4/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.450 total time=   2.1s\n",
      "[CV 5/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 5/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.442 total time=   2.5s\n",
      "[CV 1/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 4/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 5/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 1/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.436 total time=   2.9s\n",
      "[CV 2/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.402 total time=   2.8s\n",
      "[CV 3/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.437 total time=   2.4s\n",
      "[CV 4/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.450 total time=   2.5s\n",
      "[CV 5/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.445 total time=   2.6s\n",
      "Best score: 0.4963647034891182\n",
      "Best parameter set: \n",
      "\tclassify__C: 0.1\n",
      "\tclassify__loss: 'squared_hinge'\n",
      "\tclassify__penalty: 'l2'\n",
      "Test score: 0.4477611940298508\n"
     ]
    }
   ],
   "source": [
    "#perform grid search\n",
    "x_train = train_data.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "y_train = train_data['labels'].values\n",
    "\n",
    "x_test = test_data.drop('labels', axis=1)\n",
    "y_test = test_data['labels'].values\n",
    "\n",
    "grid(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for the execution of the best model that was finally obtained\n",
    "def run(fold, df, clf, x_valid_total, y_valid_total, preds_total_valid):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train = df_train.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "    y_train = df_train['labels'].values\n",
    "    \n",
    "    x_valid = df_valid.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "    y_valid = df_valid['labels'].values\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    preds_train = clf.predict(x_train)\n",
    "    preds_valid = clf.predict(x_valid)\n",
    "\n",
    "    score_train = metrics.fbeta_score(y_train, preds_train, beta=2)\n",
    "    \n",
    "    score_valid = metrics.fbeta_score(y_valid, preds_valid, beta=2)\n",
    "    print(\"Validation Fold: \" + str(fold) + \": \" + str(score_valid))\n",
    "    \n",
    "    if fold == 0:\n",
    "        x_valid_total = x_valid\n",
    "        y_valid_total = y_valid\n",
    "        preds_total_valid = preds_valid\n",
    "        \n",
    "    else:\n",
    "        x_valid_total = np.concatenate((x_valid_total, x_valid), axis=0)\n",
    "        y_valid_total = np.concatenate((y_valid_total, y_valid), axis=None)\n",
    "        preds_total_valid = np.concatenate((preds_total_valid, preds_valid), axis=None)\n",
    "    \n",
    "    return score_valid, x_valid_total, y_valid_total, preds_total_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Fold: 0: 0.5070993914807302\n",
      "Validation Fold: 1: 0.5106382978723404\n",
      "Validation Fold: 2: 0.4661016949152542\n",
      "Validation Fold: 3: 0.48283261802575106\n",
      "Validation Fold: 4: 0.5151515151515151\n",
      "Average fold score: 0.4963647034891182\n"
     ]
    }
   ],
   "source": [
    "#execute the best model that was found using grid search\n",
    "x_valid_total = None\n",
    "y_valid_total = None\n",
    "preds_total = None\n",
    "\n",
    "folds = 5\n",
    "sampling_strategy_o = 0.32\n",
    "\n",
    "if alg == 'logistic regression':\n",
    "    clf = linear_model.LogisticRegression(class_weight='balanced', solver='squared_hinge', C=0.1, penalty='l2')\n",
    "    \n",
    "if alg == 'decision tree':\n",
    "    clf = tree.DecisionTreeClassifier(random_state=0, criterion='gini', max_depth=10)\n",
    "    \n",
    "if alg == 'support vector machine':\n",
    "    clf = svm.LinearSVC(class_weight='balanced', C=0.1, loss='squared_hinge')\n",
    "    \n",
    "if lang == 'tf-idf':\n",
    "    pipe = imb_pipeline([\n",
    "                ('tfidf', column_transformer),\n",
    "                ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                ('classify', clf)\n",
    "        ])\n",
    "        \n",
    "else:\n",
    "    pipe = imb_pipeline([\n",
    "                ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                ('classify', clf)\n",
    "    ])\n",
    "\n",
    "avg = 0\n",
    "for i in range(0, folds):\n",
    "    run_fold = run(i, train_data, pipe, x_valid_total, y_valid_total, preds_total)\n",
    "    avg = avg + run_fold[0]\n",
    "    x_valid_total = run_fold[1]\n",
    "    y_valid_total = run_fold[2]\n",
    "    preds_total = run_fold[3]\n",
    "    \n",
    "avg = avg/folds\n",
    "print(\"Average fold score: \" + str(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4477611940298508\n"
     ]
    }
   ],
   "source": [
    "#determine score on test set and averaged out over validation and test set\n",
    "x_train = train_data.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "y_train = train_data['labels'].values\n",
    "\n",
    "x_test = test_data.drop('labels', axis=1)\n",
    "y_test = test_data['labels'].values\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "preds = pipe.predict(x_test)\n",
    "\n",
    "x_valid_total = np.concatenate((x_valid_total, x_test), axis=0)\n",
    "y_valid_total = np.concatenate((y_valid_total, y_test), axis=None)\n",
    "preds_total = np.concatenate((preds_total, preds), axis=None)\n",
    "\n",
    "auc = metrics.fbeta_score(y_test, preds, beta=2)\n",
    "print(\"Test score: \" + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[4004  113]\n",
      " [  55   54]]\n",
      "Normalized confusion matrix\n",
      "[[0.97255283 0.02744717]\n",
      " [0.50458716 0.49541284]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix obtained by the best model\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "        pipe,\n",
    "        pd. DataFrame(x_test),\n",
    "        y_test,\n",
    "        display_labels=le.classes_,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
