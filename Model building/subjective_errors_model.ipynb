{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection, metrics, linear_model, tree\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import scipy.sparse\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\n",
    "\n",
    "#word2vec\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('..\\\\word2vec\\\\roularta-320.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '..\\\\Data\\\\'\n",
    "\n",
    "#read data\n",
    "my_data = pd.read_csv(filepath + 'input_data_model_subj.csv', quotechar='\"', delimiter=',')\n",
    "my_train_data = pd.read_csv(filepath + 'input_data_model_subj_train.csv', quotechar='\"', delimiter=',')\n",
    "my_test_data = pd.read_csv(filepath + 'input_data_model_subj_test.csv', quotechar='\"', delimiter=',')\n",
    "\n",
    "my_train_data['test'] = False\n",
    "my_test_data['test'] = True\n",
    "my_data = my_train_data.append(my_test_data, ignore_index = True)\n",
    "\n",
    "#fill up NULL values in the original data with 0\n",
    "my_data['fraction_total_changed_intro_original'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_intro_new'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_text_original'].fillna(0, inplace=True) \n",
    "my_data['fraction_total_changed_text_new'].fillna(0, inplace=True) \n",
    "my_data['original_changed_text'].fillna('', inplace=True) \n",
    "my_data['new_changed_text'].fillna('', inplace=True) \n",
    "my_data['topic'].fillna('other', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the appropriate learning algorithm and language model\n",
    "\n",
    "#LEARNING ALGORITHM\n",
    "#alg = 'logistic regression'\n",
    "#alg = 'decision tree'\n",
    "alg = 'support vector machine'\n",
    "\n",
    "#LANGUAGE MODEL\n",
    "\n",
    "#lang = 'no text'\n",
    "lang = 'tf-idf'\n",
    "#lang = 'word2vec'\n",
    "#lang = 'bertje_full'\n",
    "#lang = 'bertje_minimized'\n",
    "#lang = 'bertje_lemmatized'\n",
    "#lang = 'sbert_full'\n",
    "#lang = 'sbert_minimized'\n",
    "#lang = 'sbert_lemmatized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    20785\n",
      "True       344\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#show distribution of positive and negative samples\n",
    "print(my_data['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the features to be inputted to the model\n",
    "\n",
    "my_data['original_time'] = pd.to_datetime(my_data['original_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "my_data['new_time'] = pd.to_datetime(my_data['new_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "my_data['first_time'] = pd.to_datetime(my_data['first_time'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "my_data['weekday_original'] = my_data['original_time'].dt.weekday\n",
    "my_data['hour_original'] = my_data['original_time'].dt.hour\n",
    "my_data['weekday_new'] = my_data['new_time'].dt.weekday\n",
    "my_data['hour_new'] = my_data['new_time'].dt.hour\n",
    "my_data['weekday_first'] = my_data['first_time'].dt.weekday\n",
    "my_data['hour_first'] = my_data['first_time'].dt.hour\n",
    "\n",
    "data_to_encode = my_data[['newspaper', 'topic', 'textpart', 'first_wordtype', 'last_wordtype']]\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe_data = pd.DataFrame(ohe.fit_transform(data_to_encode))\n",
    "\n",
    "normalized_continuous_array = ['weekday_original', 'weekday_new', 'hour_original', 'hour_new',\n",
    "    'length_original', 'length_new', 'max_version_number', \n",
    "                               'version_number_progress',\n",
    "                                 'dates_difference', \n",
    "                               'time_difference', 'original_title_length', 'original_intro_length',\n",
    "               'original_text_length', 'new_title_length', 'new_intro_length', 'new_text_length', \n",
    "                               'fraction_original_title_changed', 'fraction_new_title_changed',\n",
    "              'fraction_original_intro_changed', 'fraction_new_intro_changed',\n",
    "              'fraction_original_text_changed', 'fraction_new_text_changed', \n",
    "                                 'original_changed_fraction_text_part', 'new_changed_fraction_text_part', \n",
    "                'levenshtein_maximalized',\n",
    "                               'nr_insert_max', 'nr_delete_max', 'nr_replace_max',\n",
    "              'levenshtein_minimalized',\n",
    "                               'nr_insert_min', 'nr_delete_min', 'nr_replace_min',\n",
    "                               'jaccard', 'capitalized_equality',\n",
    "    'seqratio', 'text_overlap_original', 'text_overlap_new',\n",
    "              'stop_words_ratio',\n",
    "                               'fraction_total_changed_original', 'fraction_total_changed_new',\n",
    "                            'fraction_total_changed_title_original', 'fraction_total_changed_title_new',\n",
    "              'fraction_total_changed_intro_original', 'fraction_total_changed_intro_new',\n",
    "              'fraction_total_changed_text_original', 'fraction_total_changed_text_new',\n",
    "            'ent_original', 'original_token_length', 'adv_orig', 'noun_orig', 'point_orig', 'comma_orig',\n",
    "              'accent_orig', 'haakje_orig', 'doublepoint_orig', 'hyphen_orig', 'threepoints_orig', 'punct_orig', 'x_orig', 'propn_orig',\n",
    "              'pron_orig', 'det_orig', 'sconj_orig', 'space_orig', 'sym_orig', 'num_orig', 'adp_orig',\n",
    "              'intj_orig', 'aux_orig', 'inf_orig', 'pv_verl_ev_orig', 'pv_verl_mv_orig', 'pv_tgw_ev_orig', 'pv_tgw_mv_orig',\n",
    "                'od_prenom_orig', 'od_nom_orig', 'od_postnom_orig', 'od_vrij_orig', 'vd_vrij_orig', 'vd_prenom_orig', \n",
    "              'vd_postnom_orig', 'vd_nom_orig', 'verb_orig', 'cconj_orig', 'adj_sup_orig', 'adj_comp_orig', 'adj_basis_orig',\n",
    "              'ent_new', 'new_token_length', 'adv_new', 'noun_new', 'point_new', 'comma_new',\n",
    "              'accent_new', 'haakje_new', 'doublepoint_new', 'hyphen_new', 'threepoints_new', 'punct_new', 'x_new', 'propn_new',\n",
    "              'pron_new', 'det_new', 'sconj_new', 'space_new', 'sym_new', 'num_new', 'adp_new',\n",
    "              'intj_new', 'aux_new', 'inf_new', 'pv_verl_ev_new', 'pv_verl_mv_new', 'pv_tgw_ev_new', 'pv_tgw_mv_new',\n",
    "                'od_prenom_new', 'od_nom_new', 'od_postnom_new', 'od_vrij_new', 'vd_vrij_new', 'vd_prenom_new', \n",
    "              'vd_postnom_new', 'vd_nom_new', 'verb_new', 'cconj_new', 'adj_sup_new', 'adj_comp_new', 'adj_basis_new',  \n",
    "              'orginal_spelling_ok', 'new_spelling_ok', 'number_comparison', 'changed_position',\n",
    "                               'nr_red_parts', 'nr_green_parts', 'orig_part_of_new', 'new_part_of_orig',\n",
    "                               'one_edit_change', 'sentence_sim', 'diff_sim', \n",
    "                               'doubt_words_orig', 'doubt_words_new',\n",
    "                               'doubt_words_total',\n",
    "                               'negation_original',\n",
    "                               'negation_new', 'temporary',\n",
    "              'colors', 'days', 'currencies', 'months', 'winds', 'states', 'countries', 'cities', 'belgian', 'nationality',\n",
    "              'date_diff', 'person_diff', 'nr_full_sentences_original', 'nr_full_sentences_new',\n",
    "                               'entity_present_in_original', 'entity_present_in_new'                          \n",
    "                        ]\n",
    "\n",
    "if lang == 'bertje_full':\n",
    "    header_bertje_original = ['original_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_new = ['new_bertje_' + str(i) for i in range(0, 768)]\n",
    "    \n",
    "if lang == 'bertje_minimized':\n",
    "    header_bertje_minimized_original = ['original_minimized_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_minimized_new = ['new_minimized_bertje_' + str(i) for i in range(0, 768)]\n",
    "\n",
    "if lang == 'bertje_lemmatized':\n",
    "    header_bertje_lemmatized_original = ['original_lemmatized_bertje_' + str(i) for i in range(0, 768)]\n",
    "    header_bertje_lemmatized_new = ['new_lemmatized_bertje_' + str(i) for i in range(0, 768)]\n",
    "\n",
    "if lang == 'sbert_full':\n",
    "    header_sbert_original = ['original_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_new = ['new_sbert_' + str(i) for i in range(0, 512)]\n",
    "\n",
    "if lang == 'sbert_minimized':\n",
    "    header_sbert_minimized_original = ['original_minimized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_minimized_new = ['new_minimized_sbert_' + str(i) for i in range(0, 512)]\n",
    "\n",
    "if lang == 'sbert_lemmatized':\n",
    "    header_sbert_lemmatized_original = ['original_lemmatized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    header_sbert_lemmatized_new = ['new_lemmatized_sbert_' + str(i) for i in range(0, 512)]\n",
    "    \n",
    "boolean_features = ['double_word', 'equal_after_subst', 'globally_equal_after_subst']\n",
    "text_array_lemmatized = ['original_lemmatized_minimized_changed_text', 'new_lemmatized_minimized_changed_text']\n",
    "text_array_minimized = ['original_minimized_changed_text', 'new_minimized_changed_text']\n",
    "text_array_changed = ['original_changed_text', 'new_changed_text']\n",
    "\n",
    "text_df = my_data[text_array_lemmatized].fillna('')\n",
    "text_minimized_df = my_data[text_array_minimized].fillna('')\n",
    "my_data = my_data.replace(np.inf, 0)\n",
    "\n",
    "#normalize all continuous variables before continuing\n",
    "normalized_continuous = (my_data[normalized_continuous_array] - my_data[normalized_continuous_array].min())/(my_data[normalized_continuous_array].max() - my_data[normalized_continuous_array].min() + 0.01)\n",
    "\n",
    "if lang == 'bertje_full':\n",
    "    normalized_bertje_original = (my_data[header_bertje_original] - my_data[header_bertje_original].min())/(my_data[header_bertje_original].max() - my_data[header_bertje_original].min() + 0.01)\n",
    "    normalized_bertje_new = (my_data[header_bertje_new] - my_data[header_bertje_new].min())/(my_data[header_bertje_new].max() - my_data[header_bertje_new].min() + 0.01)\n",
    "\n",
    "if lang == 'bertje_minimized':\n",
    "    normalized_bertje_minimized_original = (my_data[header_bertje_minimized_original] - my_data[header_bertje_minimized_original].min())/(my_data[header_bertje_minimized_original].max() - my_data[header_bertje_minimized_original].min() + 0.01)\n",
    "    normalized_bertje_minimized_new = (my_data[header_bertje_minimized_new] - my_data[header_bertje_minimized_new].min())/(my_data[header_bertje_minimized_new].max() - my_data[header_bertje_minimized_new].min() + 0.01)\n",
    "    \n",
    "if lang == 'bertje_lemmatized':\n",
    "    normalized_bertje_lemmatized_original = (my_data[header_bertje_lemmatized_original] - my_data[header_bertje_lemmatized_original].min())/(my_data[header_bertje_lemmatized_original].max() - my_data[header_bertje_lemmatized_original].min() + 0.01)\n",
    "    normalized_bertje_lemmatized_new = (my_data[header_bertje_lemmatized_new] - my_data[header_bertje_lemmatized_new].min())/(my_data[header_bertje_lemmatized_new].max() - my_data[header_bertje_lemmatized_new].min() + 0.01)\n",
    "\n",
    "if lang == 'sbert_full':\n",
    "    normalized_sbert_original = (my_data[header_sbert_original] - my_data[header_sbert_original].min())/(my_data[header_sbert_original].max() - my_data[header_sbert_original].min() + 0.01)\n",
    "    normalized_sbert_new = (my_data[header_sbert_new] - my_data[header_sbert_new].min())/(my_data[header_sbert_new].max() - my_data[header_sbert_new].min() + 0.01)\n",
    "\n",
    "if lang == 'sbert_minimized':\n",
    "    normalized_sbert_minimized_original = (my_data[header_sbert_minimized_original] - my_data[header_sbert_minimized_original].min())/(my_data[header_sbert_minimized_original].max() - my_data[header_sbert_minimized_original].min() + 0.01)\n",
    "    normalized_sbert_minimized_new = (my_data[header_sbert_minimized_new] - my_data[header_sbert_minimized_new].min())/(my_data[header_sbert_minimized_new].max() - my_data[header_sbert_minimized_new].min() + 0.01)    \n",
    "    \n",
    "if lang == 'sbert_lemmatized':\n",
    "    normalized_sbert_lemmatized_original = (my_data[header_sbert_lemmatized_original] - my_data[header_sbert_lemmatized_original].min())/(my_data[header_sbert_lemmatized_original].max() - my_data[header_sbert_lemmatized_original].min() + 0.01)\n",
    "    normalized_sbert_lemmatized_new = (my_data[header_sbert_lemmatized_new] - my_data[header_sbert_lemmatized_new].min())/(my_data[header_sbert_lemmatized_new].max() - my_data[header_sbert_lemmatized_new].min() + 0.01)\n",
    "    \n",
    "boolean = my_data[boolean_features]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = pd.DataFrame({'labels': le.fit_transform(my_data['type'])})\n",
    "\n",
    "test = pd.DataFrame({'test': my_data['test']})\n",
    "\n",
    "all_data = pd.concat([ohe_data, normalized_continuous, boolean, text_minimized_df, labels, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding vector embeddings in case of word2vec\n",
    "\n",
    "if lang == 'word2vec':\n",
    "    word2vec_tokenizer = TfidfVectorizer().build_tokenizer()\n",
    "    \n",
    "    all_data[\"original_tokenized\"] = all_data.apply(lambda x: [word.lower() for word in word2vec_tokenizer(x['original_minimized_changed_text'])], axis=1)\n",
    "    all_data[\"new_tokenized\"] = all_data.apply(lambda x: [word.lower() for word in word2vec_tokenizer(x['new_minimized_changed_text'])], axis=1)\n",
    "\n",
    "    all_data[\"original_word2vec_array\"] = all_data.apply(lambda x: [word2vec_model[word] for word in x[\"original_tokenized\"] if word in word2vec_model], axis=1)\n",
    "    all_data[\"new_word2vec_array\"] = all_data.apply(lambda x: [word2vec_model[word] for word in x[\"new_tokenized\"] if word in word2vec_model], axis=1)\n",
    "\n",
    "    all_data[\"original_word2vec\"] = all_data.apply(lambda x: [float(sum(l))/len(l) for l in zip(*x[\"original_word2vec_array\"])], axis=1)\n",
    "    all_data[\"new_word2vec\"] = all_data.apply(lambda x: [float(sum(l))/len(l) for l in zip(*x[\"new_word2vec_array\"])], axis=1)\n",
    "\n",
    "    original_column_names = ['original_word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "    new_column_names = ['new_word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "    word2vec_column_names = ['word2vec_' + index for index in [str(i) for i in range(0, 320)]]\n",
    "\n",
    "    word2vec_data_original = pd.DataFrame(all_data[\"original_word2vec\"].to_list(), columns=original_column_names)\n",
    "    word2vec_data_new = pd.DataFrame(all_data[\"new_word2vec\"].to_list(), columns=new_column_names)\n",
    "    word2vec_data = pd.DataFrame(word2vec_data_original - word2vec_data_new, columns=word2vec_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSE THE APPROPRIATE MODEL\n",
    "\n",
    "if lang == 'no text':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'tf-idf':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, text_df, boolean, labels, test], axis=1)\n",
    "    \n",
    "if lang == 'word2vec':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, word2vec_data_original, word2vec_data_new, boolean, labels, test], axis=1)\n",
    "    all_data[original_column_names] = all_data[original_column_names].fillna(0)\n",
    "    all_data[new_column_names] = all_data[new_column_names].fillna(0)\n",
    "    \n",
    "if lang == 'bertje_full':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_original, normalized_bertje_new, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'bertje_minimized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_minimized_original, normalized_bertje_minimized_new, boolean, labels, test], axis=1)    \n",
    "\n",
    "if lang == 'bertje_lemmatized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_bertje_lemmatized_original, normalized_bertje_lemmatized_new, boolean, labels, test], axis=1)\n",
    "    \n",
    "if lang == 'sbert_full':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_original, normalized_sbert_new, boolean, labels, test], axis=1)\n",
    "\n",
    "if lang == 'sbert_minimized':    \n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_minimized_original, normalized_sbert_minimized_new, boolean, labels, test], axis=1)    \n",
    "\n",
    "if lang == 'sbert_lemmatized':\n",
    "    all_data = pd.concat([ohe_data, normalized_continuous, normalized_sbert_lemmatized_original, normalized_sbert_lemmatized_new, boolean, labels, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up the training data (80%) and the test data (20%)\n",
    "train_data = all_data[all_data[\"test\"]==False].iloc[:, :-1]\n",
    "test_data = all_data[all_data[\"test\"]==True].iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9503120440724202\n"
     ]
    }
   ],
   "source": [
    "#ONLY TO BE EXECUTED IN CASE OF TF-IDF\n",
    "\n",
    "#verify number of features needed for 95% threshold using LSA\n",
    "\n",
    "#transform textual data present in the atomic changes (in the attributes 'original_changed_text' and 'new_changed_text')\n",
    "#into TF-IDF features such that we have all initial features that would be used in the model\n",
    "\n",
    "if lang == 'tf-idf':\n",
    "    vectorizer_original = TfidfVectorizer()\n",
    "    vectorizer_new = TfidfVectorizer()\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        [('tfidf_original', vectorizer_original, 'original_lemmatized_minimized_changed_text'), \n",
    "        ('tfidf_new', vectorizer_new, 'new_lemmatized_minimized_changed_text')],\n",
    "        remainder='passthrough')\n",
    "\n",
    "    temp_train_data = column_transformer.fit_transform(train_data)\n",
    "\n",
    "    truncatedsvd = TruncatedSVD(n_components=1850)\n",
    "    truncatedsvd.fit(temp_train_data)\n",
    "\n",
    "    print(truncatedsvd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define f2 scorer\n",
    "def fbeta_score(y_true, y_pred):\n",
    "    return metrics.fbeta_score(y_true, y_pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the training data into five different folds in order to apply stratified k-fold cross validation\n",
    "#for the final execution of the best model\n",
    "train_data[\"kfold\"] = -1\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_, v_) in enumerate(kf.split(X = train_data, y=train_data['labels'].values)):\n",
    "    train_data.loc[v_, 'kfold'] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that implements grid search for hyperparameter optimization by selecting the optimization algorithm\n",
    "#and parameters accordingly\n",
    "def grid(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    #Grid Search Model\n",
    "    if alg == 'decision tree':\n",
    "        clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "        \n",
    "        param_grid = {\"classify__criterion\": ['entropy', 'gini', 'log_loss'],\n",
    "        \"classify__max_depth\": [2,4,6,8,10,12, 14, 16, 18, 20, 22, 24, 26, 28, 30]}\n",
    "    \n",
    "    if alg == 'logistic regression':\n",
    "        clf = linear_model.LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "        \n",
    "        param_grid = {\"classify__C\":[0.01, 0.1, 1.0], \"classify__penalty\":[\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"classify__solver\": ['newton-cg', \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}\n",
    "    \n",
    "    if alg == 'support vector machine':\n",
    "        clf = LinearSVC(class_weight=\"balanced\", random_state=0)\n",
    "        \n",
    "        param_grid = {\"classify__loss\": ['hinge', 'squared_hinge'],\n",
    "        \"classify__C\":[ 0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \"classify__penalty\":[\"l1\", \"l2\"]}\n",
    "    \n",
    "    sampling_strategy_o = 0.40\n",
    "    \n",
    "    if lang == 'tf-idf':\n",
    "        pipe = imb_pipeline([\n",
    "                    ('tfidf', column_transformer),\n",
    "                    ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                    ('classify', clf)\n",
    "            ])\n",
    "        \n",
    "    else:\n",
    "        pipe = imb_pipeline([\n",
    "                    ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                    ('classify', clf)\n",
    "        ])\n",
    "\n",
    "    \n",
    "    scorer = metrics.make_scorer(fbeta_score, greater_is_better=True, needs_threshold=False)\n",
    "\n",
    "    grid_model = model_selection.GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    refit=True,\n",
    "    verbose=10,\n",
    "    cv=5)\n",
    "    \n",
    "    grid_model.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best score: \" + str(grid_model.best_score_))\n",
    "    print(\"Best parameter set: \")\n",
    "    best_parameters = grid_model.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    best_model = grid_model.best_estimator_\n",
    "    best_model.fit(x_train, y_train)\n",
    "    preds = best_model.predict(x_test)\n",
    "    \n",
    "    score = metrics.fbeta_score(y_test, preds, beta=2)\n",
    "    print(\"Test score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 1/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 2/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 1/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 1/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.103 total time=   0.8s\n",
      "[CV 2/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.095 total time=   0.9s\n",
      "[CV 3/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.097 total time=   0.8s\n",
      "[CV 4/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.094 total time=   0.8s\n",
      "[CV 5/5; 2/24] START classify__C=1e-05, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 2/24] END classify__C=1e-05, classify__loss=hinge, classify__penalty=l2;, score=0.083 total time=   0.7s\n",
      "[CV 1/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 3/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 3/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 3/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 1/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.108 total time=   0.8s\n",
      "[CV 2/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.094 total time=   0.8s\n",
      "[CV 3/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.098 total time=   0.8s\n",
      "[CV 4/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.094 total time=   0.8s\n",
      "[CV 5/5; 4/24] START classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 4/24] END classify__C=1e-05, classify__loss=squared_hinge, classify__penalty=l2;, score=0.088 total time=   0.8s\n",
      "[CV 1/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 1/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 2/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 4/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 5/5; 5/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 5/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.099 total time=   0.8s\n",
      "[CV 2/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.089 total time=   0.7s\n",
      "[CV 3/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.089 total time=   0.8s\n",
      "[CV 4/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.090 total time=   0.8s\n",
      "[CV 5/5; 6/24] START classify__C=0.0001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 6/24] END classify__C=0.0001, classify__loss=hinge, classify__penalty=l2;, score=0.087 total time=   0.9s\n",
      "[CV 1/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 3/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 7/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 7/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 1/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.140 total time=   0.9s\n",
      "[CV 2/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.131 total time=   0.9s\n",
      "[CV 3/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.123 total time=   0.9s\n",
      "[CV 4/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.131 total time=   0.9s\n",
      "[CV 5/5; 8/24] START classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 8/24] END classify__C=0.0001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.127 total time=   0.9s\n",
      "[CV 1/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 2/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 9/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 9/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 1/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.151 total time=   0.8s\n",
      "[CV 2/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.129 total time=   0.8s\n",
      "[CV 3/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.123 total time=   0.8s\n",
      "[CV 4/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.129 total time=   0.8s\n",
      "[CV 5/5; 10/24] START classify__C=0.001, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 10/24] END classify__C=0.001, classify__loss=hinge, classify__penalty=l2;, score=0.125 total time=   0.8s\n",
      "[CV 1/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 2/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 11/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 11/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.173 total time=   0.8s\n",
      "[CV 2/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.154 total time=   1.1s\n",
      "[CV 3/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.162 total time=   0.8s\n",
      "[CV 4/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.162 total time=   0.8s\n",
      "[CV 5/5; 12/24] START classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 12/24] END classify__C=0.001, classify__loss=squared_hinge, classify__penalty=l2;, score=0.160 total time=   0.8s\n",
      "[CV 1/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 1/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 2/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 2/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 3/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 4/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 13/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 13/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.182 total time=   0.9s\n",
      "[CV 2/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.153 total time=   0.9s\n",
      "[CV 3/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.170 total time=   0.9s\n",
      "[CV 4/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.185 total time=   1.0s\n",
      "[CV 5/5; 14/24] START classify__C=0.01, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 14/24] END classify__C=0.01, classify__loss=hinge, classify__penalty=l2;, score=0.175 total time=   1.1s\n",
      "[CV 1/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 5/5; 15/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 15/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.250 total time=   0.9s\n",
      "[CV 2/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.213 total time=   1.0s\n",
      "[CV 3/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.182 total time=   1.0s\n",
      "[CV 4/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.226 total time=   0.9s\n",
      "[CV 5/5; 16/24] START classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 16/24] END classify__C=0.01, classify__loss=squared_hinge, classify__penalty=l2;, score=0.175 total time=   0.9s\n",
      "[CV 1/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 1/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 3/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 4/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.5s\n",
      "[CV 5/5; 17/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l1\n",
      "[CV 5/5; 17/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 1/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.227 total time=   2.8s\n",
      "[CV 2/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 2/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.217 total time=   3.1s\n",
      "[CV 3/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 3/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.199 total time=   3.1s\n",
      "[CV 4/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 4/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.153 total time=   4.5s\n",
      "[CV 5/5; 18/24] START classify__C=0.1, classify__loss=hinge, classify__penalty=l2\n",
      "[CV 5/5; 18/24] END classify__C=0.1, classify__loss=hinge, classify__penalty=l2;, score=0.201 total time=   3.1s\n",
      "[CV 1/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 4/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.8s\n",
      "[CV 5/5; 19/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 19/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   1.1s\n",
      "[CV 1/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.236 total time=   2.8s\n",
      "[CV 2/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.220 total time=   1.6s\n",
      "[CV 3/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.184 total time=   1.5s\n",
      "[CV 4/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.168 total time=   1.5s\n",
      "[CV 5/5; 20/24] START classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 20/24] END classify__C=0.1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.224 total time=   1.6s\n",
      "[CV 1/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 1/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 2/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 3/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 3/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 4/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 4/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 5/5; 21/24] START classify__C=1, classify__loss=hinge, classify__penalty=l1.\n",
      "[CV 5/5; 21/24] END classify__C=1, classify__loss=hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 1/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 1/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.222 total time=   3.8s\n",
      "[CV 2/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 2/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.187 total time=   3.7s\n",
      "[CV 3/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 3/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.125 total time=   3.7s\n",
      "[CV 4/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 4/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.130 total time=   3.6s\n",
      "[CV 5/5; 22/24] START classify__C=1, classify__loss=hinge, classify__penalty=l2.\n",
      "[CV 5/5; 22/24] END classify__C=1, classify__loss=hinge, classify__penalty=l2;, score=0.237 total time=   3.4s\n",
      "[CV 1/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 1/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 2/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 2/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 3/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 3/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 4/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 4/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.7s\n",
      "[CV 5/5; 23/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l1\n",
      "[CV 5/5; 23/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l1;, score=nan total time=   0.6s\n",
      "[CV 1/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 1/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.182 total time=   3.6s\n",
      "[CV 2/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 2/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.184 total time=   4.1s\n",
      "[CV 3/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 3/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.122 total time=   3.9s\n",
      "[CV 4/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 4/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.129 total time=   3.8s\n",
      "[CV 5/5; 24/24] START classify__C=1, classify__loss=squared_hinge, classify__penalty=l2\n",
      "[CV 5/5; 24/24] END classify__C=1, classify__loss=squared_hinge, classify__penalty=l2;, score=0.228 total time=   4.1s\n",
      "Best score: 0.2090483007549011\n",
      "Best parameter set: \n",
      "\tclassify__C: 0.01\n",
      "\tclassify__loss: 'squared_hinge'\n",
      "\tclassify__penalty: 'l2'\n",
      "Test score: 0.2464332036316472\n"
     ]
    }
   ],
   "source": [
    "#perform grid search\n",
    "x_train = train_data.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "y_train = train_data['labels'].values\n",
    "\n",
    "x_test = test_data.drop('labels', axis=1)\n",
    "y_test = test_data['labels'].values\n",
    "\n",
    "grid(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for the execution of the best model that was finally obtained\n",
    "def run(fold, df, clf, x_valid_total, y_valid_total, preds_total_valid):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train = df_train.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "    y_train = df_train['labels'].values\n",
    "    \n",
    "    x_valid = df_valid.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "    y_valid = df_valid['labels'].values\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    preds_train = clf.predict(x_train)\n",
    "    preds_valid = clf.predict(x_valid)\n",
    "\n",
    "    score_train = metrics.fbeta_score(y_train, preds_train, beta=2)\n",
    "    \n",
    "    score_valid = metrics.fbeta_score(y_valid, preds_valid, beta=2)\n",
    "    print(\"Validation Fold: \" + str(fold) + \": \" + str(score_valid))\n",
    "    \n",
    "    if fold == 0:\n",
    "        x_valid_total = x_valid\n",
    "        y_valid_total = y_valid\n",
    "        preds_total_valid = preds_valid\n",
    "        \n",
    "    else:\n",
    "        x_valid_total = np.concatenate((x_valid_total, x_valid), axis=0)\n",
    "        y_valid_total = np.concatenate((y_valid_total, y_valid), axis=None)\n",
    "        preds_total_valid = np.concatenate((preds_total_valid, preds_valid), axis=None)\n",
    "    \n",
    "    return score_valid, x_valid_total, y_valid_total, preds_total_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Fold: 0: 0.25\n",
      "Validation Fold: 1: 0.21258503401360546\n",
      "Validation Fold: 2: 0.1819620253164557\n",
      "Validation Fold: 3: 0.22569444444444442\n",
      "Validation Fold: 4: 0.17499999999999996\n",
      "Average fold score: 0.2090483007549011\n"
     ]
    }
   ],
   "source": [
    "#execute the best model that was found using grid search\n",
    "x_valid_total = None\n",
    "y_valid_total = None\n",
    "preds_total = None\n",
    "\n",
    "folds = 5\n",
    "sampling_strategy_o = 0.40\n",
    "\n",
    "if alg == 'logistic regression':\n",
    "    clf = linear_model.LogisticRegression(class_weight='balanced', solver='newton-cg', C=0.1, penalty='l2')\n",
    "    \n",
    "if alg == 'decision tree':\n",
    "    clf = tree.DecisionTreeClassifier(random_state=0, criterion='gini', max_depth=10)\n",
    "    \n",
    "if alg == 'support vector machine':\n",
    "    clf = svm.LinearSVC(class_weight='balanced', C=0.01, loss='squared_hinge')\n",
    "    \n",
    "if lang == 'tf-idf':\n",
    "    pipe = imb_pipeline([\n",
    "                ('tfidf', column_transformer),\n",
    "                ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                ('classify', clf)\n",
    "        ])\n",
    "        \n",
    "else:\n",
    "    pipe = imb_pipeline([\n",
    "                ('over', RandomOverSampler(sampling_strategy=sampling_strategy_o, random_state=0)),\n",
    "                ('classify', clf)\n",
    "    ])\n",
    "\n",
    "avg = 0\n",
    "for i in range(0, folds):\n",
    "    run_fold = run(i, train_data, pipe, x_valid_total, y_valid_total, preds_total)\n",
    "    avg = avg + run_fold[0]\n",
    "    x_valid_total = run_fold[1]\n",
    "    y_valid_total = run_fold[2]\n",
    "    preds_total = run_fold[3]\n",
    "    \n",
    "avg = avg/folds\n",
    "print(\"Average fold score: \" + str(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.2464332036316472\n"
     ]
    }
   ],
   "source": [
    "#determine score on test set and averaged out over validation and test set\n",
    "x_train = train_data.drop('labels', axis=1).drop('kfold', axis=1)\n",
    "y_train = train_data['labels'].values\n",
    "\n",
    "x_test = test_data.drop('labels', axis=1)\n",
    "y_test = test_data['labels'].values\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "preds = pipe.predict(x_test)\n",
    "\n",
    "x_valid_total = np.concatenate((x_valid_total, x_test), axis=0)\n",
    "y_valid_total = np.concatenate((y_valid_total, y_test), axis=None)\n",
    "preds_total = np.concatenate((preds_total, preds), axis=None)\n",
    "\n",
    "auc = metrics.fbeta_score(y_test, preds, beta=2)\n",
    "print(\"Test score: \" + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[3700  457]\n",
      " [  31   38]]\n",
      "Normalized confusion matrix\n",
      "[[0.89006495 0.10993505]\n",
      " [0.44927536 0.55072464]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix obtained by the best model\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "        pipe,\n",
    "        pd. DataFrame(x_test),\n",
    "        y_test,\n",
    "        display_labels=le.classes_,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
